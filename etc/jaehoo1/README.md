# 느려진 서비스, 어디부터 봐야 할까? - 응답 시간
응답 시간은 사용자의 요청을 처리하는 데 걸리는 시간을 의미한다.

전형적인 API 서버의 응답 시간은 다음의 시간들을 포함한다.

![](/assets/images/jaehoo1/etc/server-response-time.png)

- 서버에 연결, 서버로 데이터 전송
- 서버 실행(서버 처리 시간)
  - 로직 수행(`if`, `for` 등)(백엔드 로직)
  - DB 연동(SQL 실행)
  - 외부 API 연동
  - 응답 데이터 생성(전송)
- 서버 응답

응답 시간은 다음의 두 가지로 나누어 측정하기도 하는데
- TTFB(Time to First Byte) : 응답 데이터 중 첫 번째 바이트가 도착할 때까지 걸린 시간
- TTLB(Time to Last Byte) : 응답 데이터의 마지막 바이트가 도착할 때까지 걸린 시간

응답 데이터의 크기가 작다면 TTFB와 TTLB의 차이가 크지 않을 것이고, 파일 다운로드처럼 전송할 데이터가 크거나 네트워크 속도가 느리면 TTFB와 TTLB의 차이가 클 것이다.

서버 개발자는 주로 서버의 처리 시간을 확인하는데, 이 중 DB 연동과 내/외부 API 연동이 큰 비중을 차지한다. (서버 처리 시간 대부분의 병목)  
이러한 이유로 응답 시간을 줄일 때 DB 연동(과 API 연동) 시간에 집중한다.

## 처리량
처리량 : 단위 시간당 시스템이 처리하는 작업량
- TPS : Transaction Per Second, 초당 트랜잭션 수
- RPS : Request Per Second, 초당 요청 수

![](/assets/images/jaehoo1/etc/tps.png)

요청이 최대 TPS를 초과하면 응답 시간이 지연된다. 응답 시간의 증가는 사용자 이탈로 이어질 수 있다. 이를 방지하려면 다음 2가지 (TPS를 높이는) 방법을 고려해야 한다.
- 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기 → Scale Up / Scale Out
- 처리 시간 자체를 줄여 대기 시간 줄이기 → 성능 튜닝 / 비동기 처리 등

## DB 커넥션 풀
DB를 사용하려면 다음과 같이 3단계를 거친다.
1. DB에 연결한다.
2. 쿼리를 실행한다.
3. 사용이 끝나면 연결을 종료한다.

DB 커넥션의 생애주기:
- 데이터베이스 드라이버를 사용하여 데이터베이스에 연결
- 데이터 읽기/쓰기를 위한 TCP 소켓 열기
- 소켓을 통한 데이터 읽기/쓰기
- 연결 종료
- 소켓 닫기

네트워크에서 DB를 연결하고 종료하는 시간은 전체 응답 시간에 영향을 준다. 커넥션 풀이 없다면 애플리케이션에서 DB에 접근해야하는 요청을 처리할 때마다 커넥션을 새로 생성하여 연결하고 해제하는 과정을 반복해야 한다. 이 과정은 비용이 상당히 많이 들기 때문에 요청의 응답시간이 길어진다. 이런 문제를 피하기 위해 DB 커넥션 풀을 사용한다. **DB 커넥션 풀은 DB에 연결된 커넥션을 미리 생성해서 보관한다.** 애플리케이션은 DB 작업이 필요할 때 풀에서 커넥션을 가져와 사용하고, 작업이 끝나면 다시 풀에 반환한다. **커넥션 풀을 사용하면 이미 연결된 커넥션을 재사용하기 때문에 응답 시간이 줄어드는 장점이 있다.**

많이 사용하는 프레임워크나 언어도 DB 커넥션 풀을 지원한다. 서버 개발에서 DB 커넥션 풀을 사용하는 것은 필수라는 얘기다. **스프링 부트는 HikariCP를 커넥션 풀로 사용**하며 Go 언어는 자체적으로 DB 커넥션 풀을 지원할 정도다.

커넥션 풀은 다양한 설정을 제공한다. 그중 중요한 설정은 다음과 같다.
- 커넥션 풀 크기(또는 최소 크기, 최대 크기)
- 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기할 시간
- 커넥션 유지 시간(최대 유휴 시간, 최대 유지 시간)

**그럼 커넥션 풀 사이즈는 클 수록 좋은가?**  
커넥션을 사용하는 주체는 스레드(Thread)이기 때문에, 커넥션과 스레드를 연결지어 생각해야 한다. 만약 커넥션 풀 사이즈가 스레드 풀 사이즈보다 크면, 스레드가 모두 사용하지 못해서 리소스가 낭비된다. 반대로 커넥션 풀 사이즈가 스레드 풀 사이즈보다 작으면, 스레드가 커넥션이 반환되기를 기다려야 하기 때문에 작업이 지연된다.

커넥션 풀 사이즈와 스레드 풀 사이즈의 균형이 맞더라도, 너무 큰 사이즈로 설정하면 데이터베이스 서버, 애플리케이션 서버의 메모리와 CPU를 과도하게 사용하게 되므로 성능이 저하된다.

## 메모리 사용
메모리 사용을 줄이면 GC 시간도 줄어들 가능성이 높아진다. 예를 들어 JVM에 할당된 최대 힙 크기를 4GB에서 2GB로 줄이면 GC가 탐지하고 제거해야 할 미사용 객체의 개수와 크기도 줄어든다. 검사해야 할 객체 수가 줄어드는 만큼 GC 수행 시간도 짧아진다. 물론 실제 애플리케이션이 4GB에 가까운 메모리가 있어야 하는 데도 2GB로 줄이면 메모리 부족으로 에러가 발생할 수 있으므로 실제 메모리 사용 패턴에 맞게 최대 힙 크기를 조정해야 한다.

한 번에 대량으로 객체를 생성하는 것도 주의해야 한다. 대량으로 객체가 생성되는 것을 방지하려면 조회 범위를 제한해야 한다.

파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용한다. 다음 자바 코드처럼 파일 데이터를 한꺼번에 메모리에 로딩한 후에 응답하는 방식은 피해야 한다. 파일 크기와 동시 사용자 수에 따라 메모리 사용량이 급증할 수 있기 때문이다. 이 코드는 30MB 크기의 파일을 100명이 동시에 다운로드하면 약 3GB의 메모리가 필요하게 된다.
```java
byte[] bytes = Files.readAllBytes(Path.of("path")); // 파일을 한 번에 메모리에 로딩
out.write(bytes);
```

스트림을 활용하면 파일 처리 과정에서 필요한 메모리 크기를 줄일 수 있다. 다음은 스트림을 이용하도록 변환한 코드이다.
```java
InputStream is = Files.newInputStream(Path.of("path"));
byte[] buffer = new byte[8192]; // 8KB 메모리
int read;
while ((read = is.read(buffer, 0, 8192)) >= 0) {
    out.write(buffer, 0, read);
}
// is.transferTo(out)와 동일 코드
```

이 코드는 파일을 한 번에 읽지 않고 8KB씩 끊어서 읽는다. 동시에 100명이 다운로드를 요청하더라도 필요한 메모리는 800KB에 불과하다. 파일 전체를 한 번에 메모리에 로딩하는 방식은 총 3GB에 가까운 메모리가 필요했는데, 이와 비교하면 스트림 방식은 0.001%도 안 되는 적은 메모리만을 사용하는 셈이다.

## 응답 데이터 압축
서버는 사용자의 네트워크 속도를 제어할 수 없지만 전송하는 데이터의 크기는 제어할 수 있다. 이때 사용할 수 있는 방법이 응답 데이터를 압축해서 전송하는 것이다. 웹 서버가 전송하는 응답 데이터 중에서 HTML, CSS, JS, JSON과 같이 텍스트로 구성된 응답은 압축하면 데이터 전송량을 크게 줄일 수 있다. 실제로 텍스트 데이터를 gzip으로 압축하면 70% 이상 크기를 줄일 수 있으며 데이터 전송 크기가 줄어든 만큼 전송 시간도 빨라진다. 즉, 응답 시간이 짧아진다.

아파치나 Nginx와 같은 웹 서버는 압축 기능을 제공하고 있으므로 약간의 설정만 추가하면 즉시 효과를 볼 수 있다.
> **Accept-Encoding 요청 헤더와 Content-Encoding 응답 헤더**
> 
> 웹 브라우저나 HTTP 클라이언트는 Accept-Encoding 헤더를 통해 서버에 처리할 수 있는 압축 알고리즘을 알린다. 예를 들어 gzip, deflate 알고리즘을 사용해서 압축을 풀 수 있다면 다음과 같이 Accept-Encoding 헤더를 전송한다.
> ```text
> Accept-Encoding: gzip, deflate
> ```
>
> 웹 서버는 Accept-Encoding 헤더에 명시된 알고리즘 중에서 자신이 지원하는 방식이 있을 경우, 해당 압축 알고리즘으로 응답 데이터를 압축해서 전송한다. 이때 사용된 압축 알고리즘은 Content-Encoding 응답 헤더를 통해 클라이언트에 전달된다.

응답 데이터를 압축할 때에는 다음 사항을 고려하자.
- html, css, js, json과 같은 텍스트 형식의 응답은 압축률이 높아 효과적이다. 반면 jpeg 이미지나 zip 파일처럼 이미 압축한 데이터에는 다시 압축해도 효과가 없다. 따라서 모든 응답에 압축을 적용하지 말고 텍스트 형식의 데이터에 압축을 적용하자.
- 웹 서버에서 압축을 적용했더라도 방화벽이 이를 해제해 응답할 수 있다. 즉, 웹 서버에 압축 설정을 적용했음에도 실제 응답 데이터가 압축되지 않았다면 방화벽 설정도 확인해야 한다.

## Reference
- DB 커넥션 풀 - https://www.maeil-mail.kr/question/88


# 외부 연동이 문제일 때 살펴봐야 할 것들
연동하는 서비스에 장애가 발생하면 우리 서비스도 영향을 받는다. 서비스 간 연동이 많아질수록 연동 시스템의 품질도 함께 신경써야 한다. 이를 소홀히 하면 연동 서비스의 장애가 전체 서비스가 멈추는 장애로 이어질 수 있다.

연동 서비스의 문제를 완전히 차단하기는 어렵다. 연동 서비스가 필수인 경우도 있기 때문이다. 하지만 그 영향은 줄일 수 있다.

## 타임아웃
외부 연동에서 가장 중요한 설정 중 하나는 타임아웃이다. 위에서 처리량에 영향을 주는 요소 중 하나로 [응답 시간](#느려진-서비스-어디부터-봐야-할까---응답-시간)을 언급했는데, 타임아웃은 바로 이 응답 시간과 깊이 관련되어 있다. 연동 서비스를 호출할 때 타임아웃을 적절히 설정하지 않으면, 연동 서비스에 장애가 발생했을 때 전체 서비스의 품질이 급격히 나빠질 수 있다.

### 연결 타임아웃, 읽기 타임아웃
API 연동에서 통신 과정을 단순화해 표현하면 아래 그림처럼 연결, 요청, 응답, 종료의 4단계를 거친다.

![](/assets/images/jaehoo1/etc/connection-read-timeout.png)

첫 번째 단계는 네트워크 연결 시도 단계다. 연결에는 시간이 걸린다. 네트워크 상황이나 연결할 서버의 상태에 따라 연결에 오랜 시간이 걸릴 수 있다. 연결에 시간이 오래 걸리면 대기 시간도 함께 증가한다. 대기 시간이 무한정 길어지면 성능 문제가 발생하므로, 연결 타임아웃(connection timeout)을 설정해 연결 대기 시간을 제한해야 한다.

일단 연결이 되면 요청을 전송하고 응답을 기다리게 된다. 이때 응답을 받기까지 시간이 오래 걸리면 앞서 말한 대기 시간 문제가 다시 발생한다. 따라서 읽기 타임아웃(read timeout)을 설정해서 응답 대기 시간을 제한해야 한다.

타임아웃 시간이 너무 짧으면 연동 서비스가 정상 처리했음에도 불구하고 타임아웃 에러가 발생할 수 있다. 아래 그림은 이러한 상황을 나타낸다.

![](/assets/images/jaehoo1/etc/timeout-example.png)

1. 고객은 상품 결제를 커머스 서버에 요청한다.
2. 커머스 서버는 승인 처리를 위해 PG 서버 API를 호출한다. 이때 읽기 타임아웃을 5초로 지정한다.
3. PG 서버는 카드 결제를 위해 카드사 시스템과 통신을 시작한다. 카드사가 승인 처리하는 데 5초 이상 걸린다.
4. 커머스 서버는 PG 서버로부터 5초 동안 응답을 받지 못해 타임아웃 에러가 발생하며 상품 결제에 실패한다.
5. 커머스 서버는 고객에게 실패 응답을 전송한다.
6. 카드사 서버는 10초 만에 결제 승인에 성공하고 그 결과를 PG 서버에 응답한다.

이 과정이 끝나면 고객은 카드로는 결제했지만 상품은 구매하지 못하는 불쾌한 상황에 빠진다. 커머스 서버가 PG 서버와의 통신에서 타임아웃을 15초로 설정했다면 발생하지 않았을 문제다. 결제처럼 민감한 기능은 읽기 타임아웃 시간을 약간 길게 설정해서 간헐적으로 연동 시간이 길어지더라도 정상적으로 처리할 수 있어야 한다.

> ### 소켓 타임아웃과 읽기 타임아웃
>
> 읽기 타임아웃을 지정할 때는 실제로 설정하는 값이 무엇인지 확인해야 한다. 예를 들어 Apache HttpClient는 소켓 타임아웃을 설정한다. 소켓 타임아웃은 네트워크 패킷 단위를 기준으로 하므로, 전체 응답 시간에 대한 타임아웃을 의미하지는 않는다. 따라서 소켓 타임아웃을 5초로 지정해도 전체 응답 시간은 5초 이상 걸릴 수 있다.
>
> OkHttp는 읽기 타임아웃과는 별개로 호출 타임아웃(call timeout)을 설정할 수 있다. 호출 타임아웃은 요청 시작부터 응답까지의 전체 시간 기준으로 설정된다. 소켓 타임아웃을 5초로, 호출 타임아웃을 10초로 설정하면 패킷은 계속 수신되지만 전체 처리 시간이 오래 걸리는 경우에 타임아웃을 발생시킬 수 있다.

## 재시도
외부 연동에 실패했을 때 처리 방법 중 하나는 재시도를 하는 것이다. 네트워크 통신 과정에서 간헐적으로 연결에 실패하거나 일시적으로 응답이 느려지는 경우가 있다. 이럴 때는 재시도를 통해 연동 실패를 성공으로 바꿀 수 있다.

### 재시도 가능 조건
재시도를 통해 연동 실패를 줄일 수 있지만, 항상 재시도를 할 수 있는 것은 아니다. 연동 API를 다시 호출해도 되는 조건인지 확인해야 한다.

예를 들어 포인트 서비스가 제공하는 API를 호출해 포인트를 차감하는 상황을 생각해보자. 포인트 서비스를 호출하는 과정에서 읽기 타임아웃이 발생했을 때 재시도를 하게 되면 포인트 차감이 두 번 발생할 수 있다.

재시도를 해도 되는 조건은 다음 3가지로 정리할 수 있다.
- 단순 조회 기능
- 연결 타임아웃
- 멱등성(idempotent)을 가진 변경 기능

단순 조회 기능은 재시도를 통해 성공 확률을 높일 수 있다. 포인트 내역 조회 같은 기능은 다시 호출해도 포인트 중복 차감 같은 데이터 문제가 생기지 않는다. 일시적인 문제였다면 다시 조회할 경우 정상적으로 처리될 가능성이 높다.

연결 타임아웃도 마찬가지다. 연결 타임아웃이 발생했다는 것은 연동 서비스에 아직 연결되지 않은 상태라는 뜻이다. 연동 서비스가 요청을 처리하고 있지 않은 상태이므로, 순간적인 네트워크 문제였다면 재시도를 통해 연결에 성공할 가능성이 있다.

읽기 타임아웃은 재시도할 때 주의해야 한다. 이 경우는 이미 연동 서비스가 요청을 처리하고 있는 중이기 때문이다. 읽기 타임아웃이 발생한 상황에서 재시도를 하면 로직이 중복 수행되는 데이터 문제가 생길 수 있다.

상태를 변경하는 연동 API를 재시도할 때는 멱등성을 고려해야 한다. **멱등성**이란 **연산을 여러 번 적용해도 결과가 달라지지 않는 성질**을 말한다. 한 사용자가 여러 번 API를 실행해도 한 번만 반영된다. API를  실행하는 동안 읽기 타임아웃이 발생해서 재시도해도 데이터는 이상 상태를 갖지 않는다.

같은 API라도 실패 원인에 따라 재시도 여부를 결정해야 한다. 검증 오류가 발생했다면 재시도를 해도 동일하게 실패할 가능성이 높다. API를 호출할 때 잘못된 파라미터를 전달했다면 입력이 잘못 들어왔기 때문에 400 상태 코드를 응답할 것이다. 이때 잘못된 파라미터 요청을 다시 보내도 같은 이유로 실패하게 된다.

### 재시도 횟수와 간격
재시도할 때는 다음 2가지를 결정해야 한다.
- 재시도 횟수
- 재시도 간격

먼저 재시도 횟수를 결정한다. 재시도를 무한정 할 수는 없다. 재시도 횟수만큼 응답 시간도 함께 증가하기 때문이다. 대부분의 경우 1~2번 정도의 재시도가 적당하다. 2번 재시도를 하면 총 3번 시도한 것이 되는데, 이 모두 실패했다면 간헐적인 오류보다는 다른 근본적인 문제일 가능성이 높다. 이 경우에는 재시도해도 실패할 확률이 높다.

재시도 간격도 중요하다. 여러 차례 재시도할 때는 재시도 간격을 점진적으로 늘리기도 한다. 예를 들어 첫 번째 재시도는 1초 뒤에, 두 번째 재시도는 2초 뒤에 하는 식이다. 이를 통해 연동 서버에 가해지는 부하를 일부 완화할 수 있다.

### 재시도 폭풍(retry storm) 안티 패턴
재시도를 통해 성공 가능성을 높일 수 있지만, 반대로 연동 서비스에는 더 큰 부하를 줄 수 있다. 예를 들어 연동 서비스의 성능이 느려저서 읽기 타임아웃이 발생한 상황을 생각해보자. 이때 재시도를 하면, 연동 서비스는 같은 요청을 두 배로 받게 된다. 이전 요청을 아직 처리 중인데, 같은 클라이언트가 재시도로 또다시 요청을 보내는 것이다.

엎친 데 덮친 격으로, 성능이 느려진 상태에서 새로운 요청까지 더해지면 연동 서비스의 성능은 더 나빠진다. 따라서 재시도를 검토할 때는 연동 서비스의 성능 상황도 함께 고려해야 한다.

## 동시 요청 제한
연동 서비스가 한 번에 처리할 수 있는 동시 요청 수가 100개라고 하자. 이때 연동 서비스로 동시에 300개의 요청이 들어오면 어떻게 될까? 연동 서비스의 최대 처리량을 초과했기 때문에 응답 시간이 느려지기 시작할 것이다. 연동 서비스가 느려지면 우리 서비스도 함께 느려진다.

이런 문제는 순간적으로 트래픽이 몰릴 때 발생할 수 있다. 예를 들어 선착순 이벤트를 시작하면 사용자 트래픽이 급격히 증가한다. 이 트래픽이 연동 서비스로 그대로 전달되면, 연쇄적으로 응답 시간이 느려지는 상황이 발생할 수 있다.

연동 서비스에 임계치 이상의 요청을 보내면서 발생하는 성능 저하 문제를 완화하는 방법은 연동 서비스에 요청을 일정 수준 이상으로 보내지 않는 것이다. 연동 서비스가 동시에 처리할 수 있는 요청 개수가 100개라고 할 때, 우리 서비스가 연동 서비스로 보내는 동시 요청을 100개까지만 제한하면 연동 서비스는 성능 저하 문제 없이 안정적으로 처리할 수 있다. 연동 서비스로 보내지 않은 요청은 바로 에러를 응답한다. 503(Service Unavailable) HTTP 상태 코드를 사용하면 과부화 상황임을 클라이언트에 알려 알맞은 오류 메시지를 출력할 수 있다.

> ### 벌크헤드(Bulkhead)
> 동시 요청 수를 제한하지 않을 때 동시 요청 300개를 연동 서비스로 전달하는데, 연동 서비스의 응답이 느려지면서 우리 서비스의 응답도 함께 느려지고 우리 서비스의 나머지 기능에도 영향을 주게 된다.
>
> 동시 요청 수를 제한했다면 연동 서비스와 연동하는 요청이 동시에 300개 들어올 때, 100개는 처리되고 나머지 200개는 바로 에러 응답을 받는다. 연동 서비스와 연동하는 기능은 오류가 발생하지만, 연동 서비스를 연동하지 않는 나머지 기능은 정상 동작할 수 있다.
>
> 이렇게 동시 요청을 제한하는 방식은 벌크헤드 패턴을 활용한 것이다. 벌크헤드 패턴은 **각 구성 요소를 격리함으로써 한 구성 요소의 장애가 다른 구성 요소에 영향을 주지 않도록 하는 설계 패턴**이다.

## 서킷 브레이커
연동 서비스에 과부하가 발생해 응답을 제대로 주지 못하고 있는 상황이라고 하자. 연동 서비스가 정상화되기 전까지는 요청을 보내도 계속 에러만 발생한다. 또한, 읽기 타임아웃이 발생할 때까지 대기하느라 응답 시간도 길어질 것이다.

![](/assets/images/jaehoo1/etc/integration-service-outage.png)

B 서비스가 정상 상태가 아닐 때, A 서비스는 B 서비스에 요청을 보내지 않고 바로 에러를 응답하는 것이 낫다. 이렇게 하면 B 서비스의 문제가 A 서비스에 주는 영향(응답 시간 증가, 처리량 감소 등)을 줄일 수 있다.

또한 사용자 입장에서도 수 초를 대기하다가 에러 화면을 보는 것보다는, 빠르게 에러 화면을 보는 편이 낫다.

연동 서비스가 장애 상황일 때는 연동 대신 바로 에러를 응답하고, 정상화되었을 때 연동을 재개하면 연동 서비스의 장애가 주는 영향을 줄일 수 있다.

서킷 브레이커(circuit breaker)가 동작하는 방식이 바로 이와 같다.

서킷 브레이커는 누전 차단기와 비슷하게 동작한다. 과전류가 흐르면 차단기가 내려가 전기를 끊는 것처럼, 서킷 브레이커도 과도한 오류가 발생하면 연동을 중지시키고 바로 에러를 응답한다. 이렇게 하면 연동 서비스로의 요청 전달을 차단할 수 있다.

서킷 브레이커는 닫힘(closed), 열림(open), 반 열림(half-open)의 3가지 상태를 갖는다.

![](/assets/images/jaehoo1/etc/curcuit-breaker.png)

서킷 브레이커는 닫힘 상태(정상)로 시작한다. 닫힘 상태일 때는 모든 요청을 연동 서비스에 전달한다. 외부 연동 과정에서 오류가 발생하기 시작하면, 지정한 임계치를 초과했는지 확인한다. 실패 건수가 임계치를 초과하면 서킷 브레이커는 열림 상태가 된다. 보통 임계치는 다음 조건 중 하나를 사용한다.
- 시간 기준 오류 발생 비율: 예) 10초 동안 오류 비율이 50% 초과
- 개수 기준 오류 발생 비율: 예) 100개 요청 중 오류 비율이 50% 초과

열림 상태가 되면 연동 요청은 수행하지 않고, 바로 에러 응답을 리턴한다. 열림 상태는 지정된 시간 동안 유지된다. 이 시간이 지나면 반 열림 상태로 전환된다. 반 열림 상태가 되면 일부 요청에 한해 연동을 시도한다. 일정 개수 또는 일정 시간 동안 반 열림 상태를 유지하며, 이 기간 동안 연동에 성공하면 닫힘 상태로 복귀한다. 반대로 연동에 실패하면 다시 열림 상태로 전환되어 연동을 차단한다.

서킷 브레이커가 열려 있는 동안은 연동 서비스에 요청이 전달되지 않기 때문에 연동 서비스가 과부하 상황에서 벗어날 수 있는 기회도 생긴다.

> ### 빠른 실패
> 서킷 브레이커는 문제 상황이 감지되면 해당 기능을 더 이상 실행하지 않고 바로 실패로 처리한다. 이처럼 **실패를 빠르게 감지하고, 문제가 있는 기능을 실행하지 않고 중단시키는 방식**을 빠른 실패(fail fast)라고 한다.
>
> 빠른 실패는 장애가 발생한 기능에 부하가 더해지는 것을 방지할 뿐 아니라, 불필요한 자원 낭비를 줄여 전체 서비스의 안정성을 유지하는 데도 도움이 된다.

## 외부 연동과 DB 연동
회원 가입 요청을 처리할 때, 외부 서비스를 호출해 회원 정보를 전달하는 상황을 생각해보자. 모든 것이 정상이라면 DB에 회원 데이터가 저장되고, 외부 서비스의 저장소에도 정보가 잘 저장될 것이다. 하지만 모든 것이 항상 성공하는 것은 아니다. DB에 데이터를 저장하는 과정에서 실패할 수도 있고, 외부 서비스를 연동하는 도중에 에러가 발생할 수도 있다.

### 외부 연동과 트랜잭션 처리
DB 연동과 외부 연동을 함께 실행할 때는, 오류 발생 시 DB 트랜잭션을 어떻게 처리할지 알맞게 판단해야 한다. 다음은 흔히 발생할 수 있는 2가지 상황이다.
- [외부 연동에 실패했을 때 트랜잭션을 롤백](#외부-연동에-실패했을-때-트랜잭션을-롤백)
- [외부 연동은 성공했지만 DB 연동에 실패해 트랜잭션을 롤백](#외부-연동은-성공했는데-db-연동에-실패해서-트랜잭션을-롤백)

#### 외부 연동에 실패했을 때 트랜잭션을 롤백
먼저, 트랜잭션 범위 안에서 외부 연동에 실패한 경우, 트랜잭션을 롤백할 수 있다.

![](/assets/images/jaehoo1/etc/transaction-api-db-failure1.png)

외부 연동에 실패했을 때 트랜잭션을 롤백하면, 변경한 데이터가 DB에 반영되지 않는다. 단순한 방식이지만, 롤백을 통해 DB 데이터에 이상이 생기는 것을 방지할 수 있다.

하지만 읽기 타임아웃이 발생해 트랜잭션을 롤백할 때는, 외부 서비스가 실제로는 성공적으로 처리했을 가능성을 염두에 두어야 한다. 아래 그림은 이러한 상황을 보여준다.

![](/assets/images/jaehoo1/etc/transaction-api-db-failure2.png)

트랜잭션을 롤백했는데 외부 서비스가 실제로는 성공했을 경우, 2가지 방법 중 하나를 검토해야 한다. 첫 번째는 일정 주기로 두 시스템의 데이터가 일치하는지 확인하고 보정하는 방법이다. 예를 들어, 주문 서비스와 포인트 서비스가 하루에 한 번씩 전날 포인트 사용 내역을 비교해 불일치 건이 있는지 확인하는 식이다. 불일치 건이 발견되면 수동으로 또는 자동으로 보정한다.

두 번째는 성공 확인 API를 호출하는 방식이다. 읽기 타임아웃이 발생한 경우, 일정 시간 후에 이전 호출이 실제로 성공했는지 확인하는 API를 호출한다. 이때 성공 응답이 오면 트랜잭션을 지속하고, 실패 응답이 오면 트랜잭션을 롤백한다. 이 방식은 연동 서비스가 성공 여부를 알려주는 API를 제공할 때만 사용할 수 있다.

이 방식의 변형으로 취소 API를 호출하는 방법도 있다. 읽기 타임아웃이 발생한 뒤 일정 시간 후에 취소 API를 호출하는 것이다. 연동 서비스는 취소할 대상이 있으면 취소 처리를 수행한 뒤 성공 응답을 주고, 취소할 게 없다면 아무 동작 없이 성공 응답만 반환한다. 이 경우에는 연동 처리를 취소했으므로 트랜잭션을 롤백하면 된다.

단, 성공 확인 API나 취소 API를 호출하는 방식은 연동 서비스가 지원할 때만 사용할 수 있다. 또한, 이 API들을 호출하는 과정에서도 읽기 타임아웃이 발생할 수 있다.

따라서 두 시스템 간 데이터 일관성이 중요한 기능이라면 정기적으로 데이터 일치를 확인하는 프로세스를 갖추는 것이 바람직하다.

#### 외부 연동은 성공했는데 DB 연동에 실패해서 트랜잭션을 롤백
외부 연동은 성공했지만, DB 연동에 실패해 트랜잭션을 롤백한 경우에는 취소 API를 호출해 외부 연동을 이전 상태로 되돌리는 것이 필요하다. DB 연동에 실패했기 때문에 이 경우에는 성공 확인 API를 호출해도 의미가 없다.

![](/assets/images/jaehoo1/etc/transaction-api-db-failure3.png)

취소 API가 없거나 취소에 실패할 수도 있기 때문에 데이터 일관성이 중요한 서비스라면 일정 주기로 데이터가 맞는지 비교하는 프로세스를 갖추는 것이 좋다.

## HTTP 커넥션 풀
웹 브라우저의 개발자 도구를 활용해 인터넷 URL의 처리 시간을 분석한 결과 콘텐츠 다운로드에 걸린 전체 시간은 약 0.1초인데, 이 중 서버에 연결하는 데 걸린 시간은 0.047초로 약 47%를 차지하고 있다.

DB 커넥션 풀이 DB 연결에 걸리는 시간을 줄여 성능을 높이는 것처럼 HTTP 연결도 커넥션 풀을 사용하면 연결 시간을 줄일 수 있어 응답 속도 향상에 도움이 된다.

HTTP 커넥션 풀을 사용할 때는 다음 3가지를 고려해야 한다.
- HTTP 커넥션 풀의 크기
- 풀에서 HTTP 커넥션을 가져올 때까지 대기하는 시간
- HTTP 커넥션을 유지할 시간(keep alive)

HTTP 커넥션 풀을 사용할 때 가장 먼저 고려해야 할 값은 풀의 크기다. 풀의 크기는 연동할 서비스의 성능에 따라 결정해야 한다. 연동 서비스의 성능을 고려하지 않고 무턱대고 커넥션 풀 크기를 늘리면 순간적으로 트래픽이 몰릴 때 연동 서비스의 응답 시간이 급격히 느려질 수 있다. 그 결과, 연동 서비스의 성능 저하가 우리 서비스 전체의 응답 시간까지 느리게 만들 수 있다. 따라서 커넥션 풀의 크기를 설정할 때는 반드시 연동 서비스의 처리 능력을 고려해야 한다.

두 번째 고려 사항은 대기 시간이다. 예를 들어, HTTP 커넥션 풀의 크기가 10이라면 동시에 11개의 외부 연동 요청이 들어올 경우 10개는 커넥션을 확보해 실행되고, 남은 1개는 커넥션이 반환될 때까지 대기하게 된다. 대기 시간이 길어지면 전체 응답 시간도 함께 늘어나므로 대기 시간은 수 초 이내의 짧은 시간으로 설정하는 것이 좋다.

너무 짧게(예: 0.1초) 설정하면 일시적인 트래픽 증가에도 커넥션을 구하지 못해 에러가 발생할 수 있다. 반대로 너무 길게(예: 10초) 설정하면 연동 서버가 느려졌을 때 전체 응답 시간이 늘어나는 문제가 발생할 수 있다.

세 번째 고려 사항은 커넥션 유지 시간이다. 커넥션은 무한정 유지되지 않는다. 연동 서비스가 일정 시간 동안만 커넥션을 유지한 뒤 연결을 끊는 경우도 있다. 끊어진 커넥션을 사용하면 에러가 발생하므로 연동 서비스에 맞춰 유지 시간을 적절히 설정해야 한다. 예를 들어, HTTP/1.1에서는 서버가 Keep-Alive 헤더로 연결 유지 시간을 지정한다. 이 시간이 지나면 서버는 연결을 끊기 때문에, 클라이언트의 커넥션 풀도 이 값보다 더 오래 커넥션을 유지하면 안 된다.

## 연동 서비스 이중화
서비스가 대량 트래픽을 처리할 만큼 성장했다면 연동 서비스의 이중화를 고려해야 한다.

예를 들어 결제 서비스를 생각해보자. 쇼핑 서비스에서 결제는 핵심 기능이다. 결제가 되지 않으면 상품을 구매할 수 없기 때문이다. 이때 연동된 외부 결제 서비스에 장애가 발생하면, 장애가 발생한 시간 동안 쇼핑 서비스의 매출은 0원이 된다.

하지만 결제 서비스를 이중화해두면 한 곳에 장애가 발생해도 다른 결제 서비스를 이용해 결제를 계속 진행할 수 있다.

여력이 된다면 핵심 연동 서비스를 이중화해서 장애애 대응한다. 물론 연동 기능을 이중화하면 연동할 서비스가 늘어나고 그만큼 개발과 유지에 드는 비용도 증가한다. 즉, 비용이 배로 들 수 있다는 의미다. 그래서 연동 서비스를 이중화할지 여부를 결정할 때는 다음 2가지를 반드시 따져봐야 한다.
- 해당 기능이 서비스의 핵심인지 여부
- 이중화 비용이 감당 가능한 수준인지

핵심이 아닌 기능에 예산을 쓰는 건 쉽지 않다. 예를 들어, 쇼핑 서비스에서 결제는 핵심 기능이므로 이중화의 필요성을 설득할 수 있다. 반면에 로그 유실 방지를 위해 로그 수집 연동을 이중화하자고 설득하는 건 어렵다. 또한 재정적으로 이중화를 감당할 수 있어야 한다. 연동 서비스 장애로 인한 손실보다 이중화에 드는 비용이 더 크다면 이중화를 결정하기는 쉽지 않을 것이다.

# 비동기 연동, 언제 어떻게 써야 할까
## 동기 연동과 비동기 연동
동기(synchronous) 방식은 순차적으로 실행된다. 동기 방식은 한 작업이 끝날 때까지 다음 작업이 진행되지 않는다. 동기 방식에는 코드의 순서가 곧 실행 순서가 된다.

동기 방식은 프로그램의 흐름을 직관적으로 이해할 수 있다. 디버깅도 용이하다. 툴을 사용하면 코드를 그대로 쫓아가면서 분석할 수 있다.

하지만 동기 방식이 외부 연동을 만나면 외부 연동 실패가 전체 기능의 실패인지 확인해야 한다.

연동하는 외부 서비스의 응답 시간도 고려해야 한다. [연동 서비스의 응답 시간이 길어질수록 전체 응답 시간이 느려지게 된다.](#외부-연동이-문제일-때-살펴봐야-할-것들)

다음 작업을 진행하기 위해 반드시 외부 연동 결과가 필요한 게 아니라면, 동기 방식 대신 비동기 방식으로 연동하는 것을 고민해 볼 필요가 있다. 비동기(asynchronous) 방식은 한 작업이 끝날 때까지 기다리지 않고 바로 다음 작업을 진행할 수 있다.

생각보다 많은 연동에서 비동기 방식을 사용해도 된다. 다음은 비동기 방식으로 연동해도 크게 문제가 되지 않는 몇 가지 예다.
- 쇼핑몰에서 주문이 들어오면 판매자에게 푸시 보내기(푸시 서비스 연동)
- 학습을 완료하면 학생에게 포인트 지급(포인트 서비스 연동)
- 컨텐츠를 등록할 때 검색 서비스에도 등록(검색 서비스 연동)
- 인증 번호를 요청하면 SMS로 인증 메시지 발송(SMS 발송 서비스 연동)

이 예시들에는 몇 가지 공통적인 특징이 있다.
- 첫째, 연동에 약간의 시차가 생겨도 문제가 되지 않는다.
- 둘째, 일부 기능은 실패했을 때 재시도가 가능하다.
- 셋째, 연동에 실패했을 때 나중에 수동으로 처리할 수 있는 기능도 있다.
- 넷째, 연동에 실패했을 때 무시해도 되는 기능도 있다.

외부 연동이 4가지 특징 중 일부에 해당하면 비동기로 처리할 수 있는지 검토한다.

비동기 연동은 다양한 방식으로 구현할 수 있다.
1. [별도 스레드로 실행하기](#별도-스레드로-실행하기)
2. [메시징 시스템 이용하기](#메시징)
3. [트랜잭션 아웃박스 패턴 이용하기](#트랜잭션-아웃박스-패턴)
4. 배치로 연동하기
5. CDC 이용하기

이 외에도 다양한 방식이 존재한다.

## 별도 스레드로 실행하기
비동기 연동을 하는 가장 쉬운 방법은 별도 스레드로 실행하는 것이다. 예를 들어, 푸쉬 서비스를 비동기로 연동하고 싶다면 새로운 스레드를 생성하여 연동하는 코드를 실행할 수 있다.
```java
public OrderResult placeOrder(OrderRequest req) {
    ... // 주문 생성 처리

    // 별도 스레드를 이용해서 푸시를 비동기로 발송
    new Thread(() -> pushClient.sendPush(pushDate))
            .start();

    return successResult(...);  // 푸시 발송을 기다리지 않고 리턴
}
```

매번 스레드를 생성하는 대신 스레드 풀을 사용하는 방법도 있다.
```java
ExecutorService executor = Executors.newFixedThreadPool(50);
...
public OrderResult placeOrder(OrderRequest req) {
    ... // 주문 생성 처리

    // 스레드 풀을 이용해서 푸시를 비동기로 발송
    executor.submit(() -> pushClient.sendPush(pushData));

    return successResult(...);  // 푸시 발송을 기다리지 않고 리턴
}
```

프레임워크가 제공하는 비동기 기능을 사용하는 방법도 있다. 예를 들어, 스프링 프레임워크는 `@Async` 애노테이션을 이용한 비동기 실행 기능을 제공한다. 이 기능을 이용하여 특정 메서드를 비동기로 실행할 수 있다.
```java
public class PushService {

    @Async
    public void sendPushAsync(PushData pushData) {
        pushClient.sendPush(pushData);
        // ... 기타 코드
    }
}
```

`@Async` 애노테이션을 사용할 때는 메서드 이름에 비동기 실행과 관련된 단어를 추가하는 것이 좋다. 예를 들어, `@Async` 애노테이션이 붙은 메서드 이름이 `sendPush()`라고 가정해보자. 그럼 `sendPush()`를 호출하는 코드는 다음과 같은 형태로 작성될 것이다.
```java
public OrderResult placeOrder(OrderRequest req) {
    // 주문 생성 처리

    pushService.sendPush(pushData);

    return successResult(...);  // 푸시 발송을 기다리지 않고 리턴
}
```

이 코드를 읽는 사람은 `sendPush()` 메서드가 비동기로 실행된다는 사실을 알아채기 힘들다. `sendPush()` 메서드 코드에 `@Async` 애노테이션이 붙어 있어야만 비동기로 실행된다는 걸 알 수 있다. 비동기로 실행된다는 사실을 모른 채 `try-catch`로 익셉션 처리 코드를 추가할 수도 있다. 그러나 **비동기로 실행되기 때문에 익셉션이 발생해도 `catch` 블록은 실행되지 않는다.**
```java
public OrderResult placeOrder(OrderRequest req) {
    // 주문 생성 처리
    try {
        pushService.sendPush(pushData);
    } catch (Exception ex) {
        // sendPush()가 비동기로 실행되므로 catch 블록은 동작하지 않는다.
        // 에러 처리 코드
    }
    return successResult(...);  // 푸시 발송을 기다리지 않고 리턴
}
```

**별도 스레도르 실행하면 연동 과정에서 발생한 오류 처리에 더 신경 써야 한다. 익셉션을 전파해도 소용없기 때문이다. 별도 스레드로 실행되는 코드는 내부에서 연동 과정에서 발생한 오류를 직접 처리해야 한다.**
```java
// 비동기로 실행되는 코드는 연동 과정에서 발생하는 오류를 직접 처리해야 한다.
```java
@Async
public void sendPushAsync(PushData pushData) {
    try {
        pushClient.sendPush(pushData);
    } catch (Exception e) {
        try {
            Thread.sleep(500);
        } catch (Exception ex) {}
        try {
            pushClient.sendPush(pushData);  // 재시도를 하거나
        } catch (Exception e1) {
            // 실패를 로그로 남기거나
            ...
        }
    }
}
```

> ### 스레드와 메모리
>
> 스레드는 자체적으로 일정 크기의 메모리를 사용한다. 예를 들어, 10만 개의 푸시 메시지를 비동기로 발송하기 위해 순간적으로 10만 개의 스레드를 생성한다고 하자. 운영체제, 프로그래밍 언어, 버전에 따라 스레드 1개가 점유하는 메모리 크기는 다를 수 있지만, 최소 수 백 KB의 메모리를 사용한다. 만약 스레드 1개가 사용하는 메모리가 256KB라면, 10만 개 스레드를 생성하는 데만 약 24GB의 메모리가 필요하다(실제 차지하는 메모리는 OS나 프로그래밍 언어에 따라 다를 수 있다).
>
> 10만 개의 스레드를 생성하려면 시간도 오래 걸린다. 게다가 스레드 스케줄링에 많은 CPU 시간을 사용해서 실행 시간이 매우 느려질 수 있다.
>
> 스레드 풀을 사용하면 스레드를 일정 개수로 유지할 수 있어 메모리 사용량도 일정하게 유지된다. 미리 스레드를 생성하므로 스레드를 생성하는 시간도 단축된다. 하지만 풀에 생성한 스레드 개수보다 더 많은 작업을 동시에 실행하려면 일부 작업은 다른 작업이 끝날 때까지 대기해야 한다.
>
> 비동기로 실행할 코드가 외부 API 호출이나 DB 연동과 같은 네트워크 IO 작업이라면 자바 언어의 가상 스레드나 Go 언어의 고루틴을 사용하는 것도 방법이다. 가상 스레드나 고루틴은 실제 네이티브 스레드(OS 스레드)가 아닌 런타임에서 관리하는 경량 스레드로 적은 메모리를 사용한다. 사용하는 메모리가 적은 만큼 한 번에 만들 수 있는 스레드 개수도 많다.

## 메시징
서로 다른 시스템 간에 비동기로 연동할 때 주로 사용하는 방식은 메시징 시스템을 사용하는 것이다. 메시징 시스템은 데이터 연동이 필요한 두 시스템 사이에 위치한다.

![](/assets/images/jaehoo1/etc/messaging-async.png)

시스템 A가 시스템 B에 데이터를 전달하려면 시스템 A는 전달할 데이터를 가진 메시지를 생성해서 메시징 시스템에 전송한다. 메시징 시스템은 메시지를 다시 시스템 B에 전달하고, 시스템 B는 전달받은 데이터를 이용해서 필요한 작업을 처리한다.

시스템 A에서 시스템 B를 직접 호출하는 것과 비교하면 메시징 시스템을 사용하면서 구조가 더 복잡해졌지만, 구조가 복잡해지는 대신 다른 이점을 얻을 수 있다.

첫 번째 이점은 **두 시스템이 서로 영향을 주지 않는다**는 점이다. 시스템 A의 트래픽이 갑자기 증가하면서 전달할 데이터가 시스템 B의 처리량을 초과하는 상황을 생각해보자. 시스템 A에서 시스템 B를 직접 연동했다면 시스템 B에 성능 저하가 발생하고, 그 성능 저하는 다시 시스템 A에까지 영향을 미친다. 그러나 메시징 시스템을 사용하면 시스템 B가 느려지더라도 시스템 A는 영향을 받지 않는다. 메시징 시스템은 시스템 A가 보낸 메시지를 일단 저장하고, 시스템 B의 성능에 맞게 메시지를 전달한다. 즉, 메시징 시스템은 중간에서 메시지를 보관하는 버퍼 역할을 한다. 시스템 A의 트래픽이 급증하더라도 시스템 B는 자신의 용량에 맞게 메시지를 처리할 수 있다. 또한 시스템 B의 성능이 저하되더라도 시스템 A는 영향을 받지 않고 메시지는 메시징 시스템을 통해 전송된다.

메시징 시스템을 사용해 얻을 수 있는 두 번째 이점은 **확장이 용이하다**는 점이다. 예를 들어, 시스템 A가 시스템 C에도 데이터를 전송해야 한다고 가정하자. 만약 시스템 A가 시스템 C에 직접 데이터를 전송했다면 시스템 A에 새로운 코드를 추가해야 한다. 그러나 메시징 시스템을 사용하면 시스템 C를 메시징 시스템에 연결하기만 하면 된다. 이렇게 되면 시스템 C를 추가하기 위해 시스템 A의 코드를 수정할 필요가 없다.

![](/assets/images/jaehoo1/etc/messaging-scaling.png)

> ### 생산자(Producer)/소비자(Consumer), 게시자(Publisher)/구독자(Subscriber)
>
> 메시징 시스템에서 사용하는 용어로 생산자(Producer)와 소비자(Consumer)가 있다. 메시지를 생성해서 메시징 시스템에 보내는 측을 생산자라고 한다. 반대로 메시징 시스템으로부터 메시지를 받아 처리하는 측을 소비자라고 한다.
>
> 메시징 시스템을 사용하는 구조는 게시/구독(pub/sub) 구조라고도 표현된다. 이 구조에서 메시지를 생성하고 보내는 쪽을 게시자(Publisher)라고 부르며, 메시지를 수신하여 사용하는 쪽을 구독자(Subscriber)라고 부른다.

메시징 시스템 용도로 많이 사용되는 기술을 카프카, 래빗MQ, 레디스 pub/sub 등이 있다. 각 기술은 각기 다른 특징을 가지고 있으므로, 사용 목적에 맞는 기술을 선택해야 한다. 카프카를 고를 때 고려할 만한 몇 가지 특징은 다음과 같다.
- 높은 처리량을 자랑한다. 초당 백 만 개 이상의 메시지를 처리할 수 있다.
- 수평 확장이 용이하다. 서버(브로커), 파티션, 소비자를 늘리면 된다.
- 카프카는 메시지를 파일에 보관해서 메시지가 유실되지 않는다.
- 1개의 토픽이 여러 파티션을 가질 수 있는데, 파티션 단위로 순서를 보장한다. 하지만 토픽 수준에서는 순서를 보장할 수 없다.
- 소비자는 메시지를 언제든지 재처리할 수 있다.
- 풀(pull) 모델을 사용한다. 소비자가 카프카 브로커에서 메시지를 읽어 가는 방식이다.

다음은 래빗MQ의 주요 특징이다.
- 클러스터를 통해 처리량을 높일 수 있다. 단, 카프카보다 더 많은 자원을 필요로 한다.
- 메모리에만 메시지를 보관하는 큐 설정을 사용하면 장애 상황 시 메시지가 유실될 수 있다.
- 메시지는 큐에 등록된 순서대로 소비자에 전송된다.
- 메시지가 소비자에 전달됐는지 확인하는 기능을 제공한다.
- 푸시(push) 모델을 사용한다. 래빗MQ 브로커가 소비자에 메시지를 전송한다. 소비자의 성능이 느려지면 큐에 과부하가 걸려 전반적으로 성능 저하가 발생할 수 있다.
- 다재 다능하다. AMQP, STOMP 등 여러 프로토콜을 지원하고, 게시/구독 패턴뿐만 아니라 요청/응답, 점대점(point-to-point) 패턴을 지원한다. 또한 우선순위를 지정해서 처리 순서를 변경할 수도 있다.

마지막으로 레디스 pub/sub의 주요 특징은 다음과 같다.
- 메모리를 사용하므로 지연 시간이 짧고, 래빗MQ 대비 처리량이 높다.
- 구독자가 없으면 메시지가 유실된다.
- 기본적으로 영구 메시지를 지원하지 않는다.
- 모델이 단순해서 사용하기 쉽다.

메시지가 유실되어도 상관없다면 레디스 pub/sub 기능을 고려해보자. 카프카나 래빗MQ에 비해 사용법이 간단하고, 적은 장비로 높은 성능을 낼 수 있다. 트래픽이 대량으로 발생한다면 카프카를 고려하자. 참고로 여기서 말하는 대량 트래픽은 초당 수 십만에서 수 백만 이상의 메시지를 말한다. 트래픽 규모가 크지 않고 메시지를 정확하게 순서대로 소비자에게 전달해야 하거나 AMQP나 STOMP 프로토콜로 연동해야 한다면 래빗MQ를 고려한다.

이 외에 NATS, 액티브MQ, 로켓MQ, 펄사 등을 메시징 시스템으로 사용할 수 있다. 클라우드가 제공하는 메시징 시스템도 좋은 선택이 될 수 있다. 예를 들어 AWS가 제공하는 SQS를 메시징 용도로 사용할 수 있다.

### 메시지 생성 측 고려 사항
메시지를 생성할 때 고려할 점은 메시지 유실에 대한 것이다. 예를 들어 메시지 전송 과정에서 타임아웃이 발생할 수 있다. 타임아웃 문제는 생산자와 메시징 시스템 간의 네트워크 연결이 불안정하면 언제든지 발생할 수 있다. 이때 오류 처리를 위해 선택할 수 있는 방법에는 다음 3가지가 있다.
- 무시한다.
  - 메시지의 용도에 따라 유실이 일부 허용될 수 있다.
- 재시도한다.
  - 메시지 전송을 재시도하는 과정에서 중복된 메시지가 전송될 수 있다.
  - 메시징 시스템이 중복 수신을 방지하는 기능을 제공하지 않으면 메시지 소비자가 중복 메시지를 알맞게 처리해야 한다.
  - 메시지마다 고유 식별자를 사용하면 메시지 소비자가 중복 메시지 여부를 판단하는 데 도움이 된다.
- 실패 로그를 남긴다.
  - 로그는 나중에 후처리를 하는 데 사용된다.
  - 실패 로그는 DB에 저장할 수도 있고 파일에 남길 수도 있다.
  - 실패 로그는 후처리에 필요한 데이터를 담고 있어야 한다.

메시지 생산자는 DB 트랜잭션과의 연동도 고려해야 한다. DB 트랜잭션에 실패했는데 메시지가 발송되면 잘못된 데이터가 전달될 수도 있기 때문이다.

![](/assets/images/jaehoo1/etc/db-transaction-rollback-after-message-send.png)

잘못된 메시지가 전송되는 문제를 방지하려면 트랜잭션이 끝난 뒤에 메시지를 전송해야 한다. 이렇게 하면 메시지가 유효한 데이터를 포함할 수 있게 된다.

![](/assets/images/jaehoo1/etc/send-message-after-db-transaction.png)

> ### 글로벌 트랜잭션과 메시지 연동
>
> 글로벌 트랜잭션(global transaction)을 사용하면 여러 자원(여러 DB)에 대한 변경을 한 트랜잭션으로 묶어서 처리할 수 있다. 예를 들어 A DB는 성공적으로 처리했는데 B DB를 처리할 때 오류가 발생하면 A와 B를 모두 롤백할 수 있다. 글로벌 트랜잭션을 구현하는 알고리즘으로 2단계 커밋(2-Phase Commit)을 사용하는데, 그래서 글로벌 트랜잭션을 2PC라고 표현하기도 한다.
>
> 글로벌 트랜잭션을 지원하는 메시징 시스템도 있다. 액티브MQ가 이에 해당한다. 액티브MQ를 사용하면 DB 수정과 메시지 전송/처리를 한 트랜잭션으로 묶을 수 있다. 즉 메시지 전송에 실패하면 DB를 롤백하거나 DB가 롤백되면 메시지 전송을 취소할 수 있다. 글로벌 트랜잭션을 지원하는 메시징 시스템을 사용하면 실패에 대한 대응 처리를 단순화할 수 있다.
>
> 하지만 모든 메시징 시스템이 글로벌 트랜잭션을 지원하는 것은 아니다. 게다가 글로벌 트랜잭션을 사용하면 성능에 영향을 준다. 2단계 커밋을 처리하는 과정이 추가되면서 처리 속도가 느려지기 때문이다. 커밋 과정이 길어지는 만큼 동시에 처리할 수 있는 요청이 줄어들게 된다.
>
> 글로벌 트랜잭션이 반드시 필요한 상황이 아니라면 DB 처리와 메시지 연동을 묶지 말자. DB에 데이터를 반영한 뒤에 메시지를 최대한 유실 없이 보내고 싶다면 [트랜잭션 아웃박스 패턴](#트랜잭션-아웃박스-패턴)을 검토해보자.

### 메시지 소비 측 고려 사항
메시지 소비자는 다음 2가지 이유로 동일 메시지를 중복해서 처리할 수 있다.
- 메시지 생산자가 같은 데이터를 가진 메시지를 메시징 시스템에 두 번 전송
- 소비자가 메시지를 처리하는 과정에서 오류가 발생해서 메시지 재수신

메시지 생산자가 동일한 데이터를 가진 메시지를 두 번 이상 메시징 시스템에 전송하면 메시지 수신자는 중복해서 메시지를 처리하는 것과 같다. 수신자 입장에서 동일 데이터를 가진 중복 메시지를 처리하는 방법은 메시지에 고유한 ID를 부여해서 이미 처리했는지 여부를 추적하는 것이다. 이를 통해 이미 처리한 메시지는 다시 처리하지 않고 무시할 수 있다.
```java
// 고유의 메시지 ID를 사용했을 때의 카프카 소비자 코드 구조 예
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        Message m = messageConverter.convert(record.value());
        if (checkAlreadyHandled(m.getId())) {   // 이미 처리했는지 확인
            continue;   // 처리하지 않고 무시함
        }
        handle(m);
        recordHandledLog(m.getId());    // 처리 여부 기록
    }
    ...
}
```

이 방식을 사용하려면 메시지 생산자는 메시지마다 고유의 ID를 부여해야 한다. 그래야 같은 메시지를 중복해서 발송할 때 동일한 메시지ID를 유지할 수 있기 때문이다.

메시지를 처리했는지 여부는 DB 테이블에 기록하거나 메모리에 집합(`Set<>`)으로 관리하면 된다. 메모리로 관리할 때는 메모리 부족 에러가 발생하는 것을 막기 위해 일정 개수의 메시지 ID만 유지한다.

메시지 재수신이 가능한 경우 소비자가 메시지를 처리하는 과정에서 오류가 발생하면 재처리를 위해 메시지를 다시 수신할 수 있다. 예를 들어 메시지 처리를 위해 외부 API를 호출했는데 읽기 타임아웃이 발생할 수 있다. 이때 소비자는 메시지 처리에 실패했다고 생각하고 메시징 시스템으로부터 같은 메시지를 다시 수신해서 재시도할 수 있다. 하지만 외부 API를 호출했을 때 읽기 타임아웃이 발생하면 성공했을 가능성이 있다. 실제로 성공했다면 수신자는 외부 API를 중복해서 두 번 호출하게 된다.

메시지 재수신에 따른 중복 처리를 대응하는 방법은 [멱등성](#재시도-가능-조건)을 갖도록 API를 구현하는 것이다. API가 멱등성을 가지면 동일 요청을 여러 번 해도 결과가 바뀌지 않는다.

중복 메시지 처리와 함께 메시지 소비자를 구현할 때 고려할 점은 메시지를 잘 소비하고 있는지 모니터링 하는 것이다. 메시지 소비자의 처리 속도가 갑자기 느려지면 큐에 메시지가 계속 쌓이게 된다. 메시징 시스템에 따라 큐가 가득 차면 생산자가 메시지를 큐에 넣지 못하게 막는 상황도 발생할 수 있다. 소비자의 성능 저하가 생산자까지 영향을 줄 수 있는 것이다. 또한 생산자에 영향은 주지 않더라도 메시지 처리가 늦어지면서 사용자는 원하는 기능이 동작하지 않아 불편을 겪게 된다.

### 메시지 종류: 이벤트와 커맨드
메시지에는 크게 2가지 종류가 있다. 하나는 이벤트(event)이고, 다른 하나는 커맨드(command)이다. 아래는 이벤트 메시지와 커맨드 메시지의 예시다.
|<center>이벤트</center>|<center>커맨드</center>|
|---|---|
|<ul><li>주문함</li><li>로그인에 실패함</li><li>상품 정보를 조회함</li><li>배송을 완료함</li></ul>|<ul><li>포인트 지급하기</li><li>로그인 차단하기</li><li>배송 완료 문자 발송하기</li></ul>|

**이벤트**는 **어떤 일이 발생했음을 알려주는 메시지**다. '주문함' 이벤트는 주문이 생성됐다는 사실을 의미하고, '배송을 완료함' 이벤트는 물건이 고객에게 전달됐다는 사실을 의미한다. 이 두 이벤트는 상태(데이터) 변경과 관련이 있다. '주문함' 이벤트는 새로운 주문이 생성됐을 때 발생하고, '배송을 완료함' 이벤트는 물건 상태가 '배송 중'에서 '배송 완료'로 바뀌었을 때 발생한다.

'로그인에 실패함' 이벤트나 '상품 정보를 조회함' 이벤트처럼 어떤 활동이 일어났다는 사실을 나타내는 경우도 있다. 예를 들어 사용자가 로그인에 실패했을 때 사용자 데이터는 변경되지 않을 수 있다. 즉 사용자의 상태는 그대로일 수 있다. 하지만 사용자의 활동 결과로 '로그인에 실패함' 이벤트는 발생한다.

**커맨드**는 **무언가를 요청하는 메시지**다. 커맨드 메시지를 수신하는 소비자는 메시지로 요구한 기능을 실행한다. 예를 들어 '포인트 지급하기' 메시지를 받은 소비자는 포인트를 지급한다. '배송 완료 문자 발송하기' 메시지를 받은 소비자는 대상자에게 배송이 완료됐다는 문자를 발송한다.

**커맨드 메시지**는 **메시지를 수신할 축의 기능 실행에 초점이 맞춰져 있다. 즉 수신자가 정해져 있다.** '포인트 지급하기' 메시지를 포인트 서비스가 아닌 게시글 서비스가 받는다고 해보자. 게시글 서비스는 해당 메시지를 수신해도 의미 있는 기능을 수행할 수 없다.

반면에 **이벤트 메시지**는 **정해진 수신자가 없다. 발생한 사건에 관심이 있는 소비자가 메시지를 수신하는 방식**이다. 예를 들어 '배송을 완료함' 이벤트 메시지를 생각해보자. 이 메시지는 문자를 보내라는 명령을 담고 있는 것이 아니라, 배송이 완료됐다는 사실만을 담고 있다. 따라서 배송 완료 문자를 보낼지 여부는 메시지를 수신한 소비자 쪽에서 결정한다.

![](/assets/images/jaehoo1/etc/consuming-message-when-event-occured.png)

이벤트 메시지는 **소비자 확장에 적합**하다. 예를 들어 배송을 완료했을 때 문자를 발송하고, 추가로 주문 상태도 변경하고 싶다면 위 그림처럼 '배송 완료함' 메시지를 주문 서비스가 수신하도록 구성하면 된다. 주문 서비스는 '배송 완료함' 메시지를 수신하면 해당 주문의 상태를 변경하면 된다. 또, 주문부터 배송 완료까지의 과정을 분석하는 서비스를 만든다고 하면, 이 서비스 역시 '배송 완료함' 메시지를 수신해서 배송 완료 시점을 기록하고 분석에 사용할 수 있다.

> ### 궁극적 일관성(eventual consistency)
>
> 비동기 연동을 설명할 때 자주 등장하는 용어 중 하나가 궁극적 일관성(eventual consistency)이다. 문서에 따라 최종적 일관성이나 결과적 일관성이라고 표현하기도 한다. 궁극적 일관성은 일관성 모델 중 하나로, 주로 분산 시스템에서 데이터 복제를 다룰 때 사용된다. 이 모델은 두 데이터 저장소 간의 일관성을 보장하긴 하지만, 즉시가 아닌 일정 시간이 지난 후에야 일관성이 맞춰진다는 특징을 가진다. 즉, 일시적으로는 두 저장소 간에 데이터 불일치가 발생할 수 있다는 뜻이다.
>
> 비동기 메시징 방식도 이 궁극적 일관성과 유사한 특성을 갖는다. 예를 들어 위 그림처럼 배송 서비스에서 배송 상태를 완료로 변경하더라도, 해당 변경 내용이 메시지를 통해 주문 서비스로 전달되기 전까지는 주문 서비스의 상태는 여전히 배송 중일 수 있다. 이처럼 배송 완료 메시지가 전파되기 전까지는 두 시스템 간의 상태가 서로 불일치할 수 있다.

## 트랜잭션 아웃박스 패턴
[메시지 생성 시 고려 사항](#메시지-생성-측-고려-사항)에서, 잘못된 메시지 발송을 막기 위해 DB 트랜잭션이 완료된 후 메시지를 전송하자는 내용을 언급했었다. 그런데 이렇게 해도 완벽하지는 않다. 메시지를 전송하기 위한 코드에 재시도나 예외 처리를 넣더라도 메시징 시스템 연동이 실패할 수 있기 때문이다.

**메시지 데이터 자체가 유실되지 않도록** 보장하는 방법은 먼저 **해당 데이터를 DB에 안전하게 저장해**두는 것이다. 그 뒤, **저장된 메시지를 읽어 메시징 시스템에 전송**하면 된다. 이처럼 **메시지 데이터를 DB에 보관하는 방식**이 바로 트랜잭션 아웃박스 패턴(Transactional Outbox Pattern)의 핵심이다.

트랜잭션 아웃박스 패턴은 하나의 DB 트랜잭션 내에서 다음 2가지 작업을 수행한다.
- 실제 업무 로직에 필요한 DB 변경 작업을 수행한다.
- 메시지 데이터를 아웃박스 테이블에 추가한다.

아웃박스 테이블에 쌓인 메시지 데이터는 별도의 메시지 중계 프로세스가 주기적으로 읽어서 메시징 시스템에 전송한다.

![](/assets/images/jaehoo1/etc/transaction-outbox-pattern.png)

DB 트랜잭션 범위에서 아웃박스 테이블에 메시지 데이터를 추가하므로 메시지 데이터가 유실되지 않는다. 트랜잭션을 롤백하면 메시지 데이터도 함께 롤백되므로 잘못된 메시지 데이터가 전송될 일도 없다.

메시지 중계 서비스는 위 그림의 과정5~과정7을 반복한다. 발송하지 않은 메시지 데이터를 조회해서 메시징 시스템에 전송하고, 전송에 성공하면 전송 완료 처리를 한다. 이렇게 하면 같은 메시지가 두 번 이상 전송되는 일을 최대한 막을 수 있다.

코드는 다음과 같은 형태를 갖는다.
```java
// 이 메서드를 주기적으로 호출해서 메시지 전송
public void processMessages() {
    // 아웃박스 테이블에서 대기 메시지 데이터를 순서대로 조회함
    List<MessageData> waitingMessages = selectWaitingMessages();

    for (MessageData m : waitingMessages) {
        try {
            sendMessage(m);         // 메시지를 전송함
            markDone(m.getId());    // 발송 완료 표시함
        } catch (Exception ex) {
            handleError(ex);    // 메시지 발송에 실패한 경우 후속 처리함
            break;              // 에러가 났을 때 멈춤. 이유는 순서대로 발송하기 위함
        }
    }
}
```

대기 메시지를 10개 읽어왔는데 중간에 5번째 메시지를 전송할 때 에러가 발생했다고 하자. 이때 중단하지 않고 6번째 이후 메시지를 발송하면 메시지 생성 순서와 다르게 메시지가 발송된다. 메시지 전송 순서가 중요하다면 이 점에 유의해야 한다.

발송 완료를 표시하는 방법은 2가지가 있다. 하나는 아웃박스 테이블에 발송 상태 칼럼을 두는 것이다. 이 칼럼은 3가지 상태(발송 대기, 발송 완료, 발송 실패)를 갖는다. 발송 대기 상태를 갖는 데이터를 조회하고 발송에 성공하면 발송 완료로 변경하는 식이다.
```sql
-- 발송 대기 목록을 조회
select *
from outbox
where status = 'WAITING'
order by id asc
limit 100;
```
```sql
-- 발송에 성공하면 상태를 완료로 변경
update outbox
set status = 'DONE'
where id = #{id};
```

발송 완료를 표기하는 또 다른 방법은 메시지 중계 서비스가 성공적으로 전송한 마지막 메시지 ID를 별도로 기록하는 방식이다. 예를 들어 파일이나 별도의 테이블에 메시지 ID를 저장해두고, 다음번 대기 메시지를 조회할 때 이 ID 이후의 메시지만 선택하는 것이다.

### 아웃박스 테이블 구조
상황에 맞게 변형
|<center>칼럼</center>|<center>타입</center>|<center>설명</center>|
|:---:|:---:|---|
|Id|`big int`|단순 증가 값(PK). 저장된 순서대로 증가하는 값을 사용한다.|
|messageId|`varchar`|메시지 고유 ID(고유키)|
|messageType|`varchar`|메시지 타입|
|payload|`clob`|메시지 데이터|
|status|`varchar`|이벤트 처리 상태로 다음 세 값을 가진다.<br/>- WAITING(대기)<br/>- DONE(완료)<br/>- FAILED(실패함)|
|failCount|`int`|실패 횟수|
|occuredAt|`timestamp`|메시지 발생 시간|
|processedAt|`timestamp`|메시지 처리 시간|
|failedAt|`timestamp`|마지막 실패 시간|

messageType은 메시지의 종류를 구분하기 위한 식별자이다. 'LoginFailed', 'OrderPlaced'와 같은 이름을 메시지 타입으로 사용한다. 메시지 소비자는 이 메시지 타입을 이용해 알맞은 처리를 수행한다. payload는 메시지의 데이터를 저장한다. JSON이나 XML과 같은 형식을 사용해서 데이터를 담는다.

status 칼럼은 '대기', '완료', '실패함'의 3가지 상태를 갖는다. 대기 상태인 메시지 데이터만 조회하기 때문에, 어떤 조건에서 '실패함' 상태로 바꿀지 결정해야 한다. 실패 횟수를 기준으로 자동으로 상태를 변경할 수도 있고, 상태를 모니터링하다가 수동으로 변경할 수도 있다. 예를 들어 메시지 발송에 5회 실패하면 실패함 상태로 바꾸고 다음 메시지를 처리할 수 있다. 또는 실패 횟수가 10회를 넘어가면, 모니터링 시스템을 통해 메시지 발송이 지연되고 있다는 사실을 운영팀에 알리고, 운영팀이 수동으로 실패함 상태로 바꾸도록 할 수도 있다.

'실패함' 상태로 바뀐 메시지는 알맞은 후속 조치를 해야 한다. 후속 조치를 하지 않으면 시스템간 데이터 일관성이 깨질 수 있기 때문이다. memo나 remark와 같은 칼럼을 추가해서 실패 메시지를 아웃박스 테이블에 기록하면, 실패 이유를 파악하는 데 도움이 된다.

status의 값으로 '제외함(EXCLUDED)'을 추가할 수도 있다. 이는 실패가 아니라 수동으로 특정 메시지를 전송하고 싶지 않을 때 사용할 수 있다.

> 메시지 발송에 실패했다고 해서 바로 '실패함' 상태로 바꾸지는 말자. 일시적으로 문제가 발생한 것이라면 한두 차례 재시도를 통해 성공적으로 메시지를 발송할 수 있기 때문이다.

## 배치 전송
배치 전송은 데이터를 비동기로 연동하는 가장 전통적인 방법이라고 할 수 있다. 메시징 시스템이 거의 실시간으로 데이터를 연동한다면, 배치는 일정 간격으로 데이터를 전송한다. 예를 들어 결제 승인 데이터를 모아서 다음 날 보내거나, 택배 발송 요청 데이터를 1시간 간격으로 보내는 식이다.

파일로 데이터를 주고받는 시스템은 형식 외에도 다음 항목들을 함께 정해야 한다.
- 송수신 주체
- 시간
- 경로

파일 생산자와 파일 소비자 중 누가 전송을 담당할지는 미리 협의해야 한다. 정해진 규칙은 없고, 두 시스템을 운영하는 조직이 상황에 맞게 조율하면 된다.

시간도 중요한 요소다. 소비자 시스템은 특정 시점에 데이터를 필요로 한다. 예를 들어, 업무일 기준으로 매월 5일까지 정산을 마쳐야 하는 조직이라면, 그 전에 월 단위 데이터를 받아야 한다. 정해진 시점까지 데이터를 받지 못해 업무가 지연되면 결국 개발팀에 불만이 쏟아지게 된다.

배치 파일은 데이터 누락 등 오류에 대응할 수 있는 시간을 벌기 위해 근무가 시작되는 오전 시간대에 전송을 처리할 때가 많다. 하지만 생산자 시스템이 글로벌 서비스라면 국내 시간대가 아닌 다른 시간대를 기준으로 파일을 받아야 할 때도 있다. 이 경우 생산자 시스템이 보내줄 수 있는 시간에 맞춰 소비자 시스템의 처리 시간을 변경해야 한다. 경로와 파일 이름 규칙도 맞춘다. 한 시스템이 여러 서비스로부터 파일을 받을 수 있는데, 이 경우 파일이 저장될 경로나 이름이 충돌하지 않도록 규칙을 정한다.

생산자가 소비자로 파일을 업로드할 경우 소비자는 다음과 같은 방식으로 동작한다.
1. 지정한 경로에 파일이 존재하는지 확인한다.
2. 파일이 존재하면 파일로부터 데이터를 읽어온다.
3. 파일이 없으면 알맞게 후처리한다.
4. 읽어온 데이터를 시스템에 반영한다.
5. 처리를 완료한 파일은 다른 폴더로 옮긴다.

소비자는 처리가 끝나면 파일을 다른 폴더로 이동시킨다. 이렇게 해야 같은 파일이 중복 처리되는 것을 막을 수 있다. 바로 삭제하지 않고 다른 폴더로 백업해 두면 재처리가 필요할 때 활용할 수 있다.

파일 대신 API를 이용해서 데이터를 일괄로 전송할 때도 있다. API를 사용함녀 파일 생성, 파일 전송, 파일 처리 과정이 없으므로 구현이 더 단순해지는 장점이 있다. 데이터 크기가 작거나 처리 항목이 적을 때 API를 이용한 데이터 전송 방식을 고려할 수 있다.

배치 전송의 또 다른 방식은 읽기 전용으로 DB를 열어주는 것이다. 같은 조직 내에서 데이터를 전달할 때 이 방식을 사용할 수 있다. 개발 시간이 부족할 때 선택할 수 있는 방법이다.

### 재처리 기능 만들기
파일을 지정한 시간에 전송하지 못할 때가 있다. 파일을 생성하는 과정에서 오류가 발생하거나, 네트워크 상태가 좋지 않아 전송하지 못하는 경우도 있다. 어떤 이유에서든 전송에 실패하면 일정 시간 후에 재전송하는 기능을 구현해 두자. 한두 번 정도만 재시도해도 수작업으로 재처리하는 번거로움을 상당히 줄일 수 있다.

재시도를 했음에도 실패하는 경우도 있다. 이럴 때를 대비해서 수동으로 배치를 쉽게 실행할 수 있도록 명령어나 API를 만들어 두자. 문제가 생겼을 때 빠르고 편하게 배치를 재실행할 수 있다.

## CDC(Change Data Capture)
CDC는 [위키피디아](https://ko.wikipedia.org/wiki/%EB%B3%80%EA%B2%BD_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%BA%A1%EC%B2%98)에서 다음과 같이 정의하고 있다.
- 변경된 데이터를 추적하고 판별해서 변경된 데이터로 작업을 수행할 수 있도록 하는 소프트웨어 설계 패턴

오라클이나 MySQL 같은 DBMS는 데이터가 변경되면 그 변경 내용을 통지하는 기능을 제공한다. CDC는 이 기능을 활용해서 구현한다. CDC 패턴에서는 그림처럼 3개의 구성 요소가 등장한다.

![](/assets/images/jaehoo1/etc/cdc-pattern-flow.png)

`INSERT`, `UPDATE`, `DELETE`(CUD) 쿼리를 실행하면 DB의 데이터가 변경된다. DB는 변경된 데이터를 CDC 처리기에 전송한다. DB는 커밋된 데이터만 변경된 순서에 맞게 전달한다. CDC 처리기에는 롤백된 데이터가 전달되지 않는다. 또한 잘못된 순서로 데이터가 전달되는 일도 없다.

변경 데이터는 레코드 단위로 전달된다. 예를 들어 1개 레코드를 추가하고 2개 레코드를 수정한 다음 3개 레코드를 삭제했다면 총 6개 레코드에 대한 변경분이 CDC 처리기에 전달된다. 이 변경분 데이터는 추가인지 수정인지 삭제인지를 구분할 수 있는 플래그를 갖는다. 수정인 경우에는 변경된 칼럼의 이전 값과 이후 값이 포함되어 어떤 칼럼이 어떻게 변경됐는지 확인할 수 있다.

CDC 처리기는 전달받은 변경 데이터를 확인하고 가공한 뒤에 대상 시스템에 전파한다. 이 CDC 처리기는 크게 2가지 형태로 대상 시스템에 변경 데이터를 전파한다.
1. 변경 데이터를 그대로 대상 시스템에 전파
2. 변경 데이터를 가공/변환해서 대상 시스템에 전파

목적에 따라 CDC 처리기는 DB, 메시징 시스템, API 등 다양한 대상에 데이터를 전파할 수 있다. 두 시스템 간 데이터 동기화가 목적이라면 단순히 DB와 DB 사이에 CDC를 두어 데이터를 복제할 수 있다.

![](/assets/images/jaehoo1/etc/db-data-replication-by-cdc.png)

메시징 시스템에 데이터를 전파하면 여러 시스템에 변경된 데이터를 전달할 수 있어 확장에 유리하다.

![](/assets/images/jaehoo1/etc/cdc-messaging.png)

> ### CDC와 이벤트
>
> CDC는 데이터의 변경 분을 전달한다. 이는 어떤 일이 발생했음을 알려주는 이벤트 메시지에 가깝다. 하지만 이벤트처럼 정확하게 의미를 전달하지는 못한다. 데이터의 변경 분을 통해서 의미를 도출할 수 있을 뿐이다. 예를 들어 '회원 암호 초기화함' 이벤트는 암호를 초기화했다는 것을 분명하게 나타내지만 '회원 테이블 데이터 변경: 이전 암호, 이후 암호'는 암호가 초기화됐다는 사실을 드러내지 않는다. 단지 암호 컬럼 값이 변경됐다는 것만 알 수 있다. 암호를 변경한 주체를 표기하는 칼럼이 있다면, 그 칼럼을 조합해서 암호를 회원이 변경했는지 시스템이 초기화했는지 간접적으로 알 수 있다.

### CDC와 데이터 위치
CDC 처리기는 변경 데이터를 어디까지 처리했는지 기록해야 한다. 예를 들어 MySQL은 바이너리 로그를 이용해서 CDC를 구현하는데, 각 로그 항목은 변경된 데이터와 로그 파일에서의 위치(포지션) 값을 갖는다. 이 위치를 기록해야 CDC 처리기를 재시작할 때 마지막으로 조회한 로그부터 읽어올 수 있다. 이 위치를 기록하지 않으면 마지막 로그 데이터부터 읽어와야 하는데, 이 경우 CDC 처리기를 재시작하는 시간 동안 발생한 변경 데이터를 놓치게 된다.