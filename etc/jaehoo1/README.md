# 느려진 서비스, 어디부터 봐야 할까? - 응답 시간
응답 시간은 사용자의 요청을 처리하는 데 걸리는 시간을 의미한다.

전형적인 API 서버의 응답 시간은 다음의 시간들을 포함한다.

![](/assets/images/jaehoo1/etc/server-response-time.png)

- 서버에 연결, 서버로 데이터 전송
- 서버 실행(서버 처리 시간)
  - 로직 수행(`if`, `for` 등)(백엔드 로직)
  - DB 연동(SQL 실행)
  - 외부 API 연동
  - 응답 데이터 생성(전송)
- 서버 응답

응답 시간은 다음의 두 가지로 나누어 측정하기도 하는데
- TTFB(Time to First Byte) : 응답 데이터 중 첫 번째 바이트가 도착할 때까지 걸린 시간
- TTLB(Time to Last Byte) : 응답 데이터의 마지막 바이트가 도착할 때까지 걸린 시간

응답 데이터의 크기가 작다면 TTFB와 TTLB의 차이가 크지 않을 것이고, 파일 다운로드처럼 전송할 데이터가 크거나 네트워크 속도가 느리면 TTFB와 TTLB의 차이가 클 것이다.

서버 개발자는 주로 서버의 처리 시간을 확인하는데, 이 중 DB 연동과 내/외부 API 연동이 큰 비중을 차지한다. (서버 처리 시간 대부분의 병목)  
이러한 이유로 응답 시간을 줄일 때 DB 연동(과 API 연동) 시간에 집중한다.

## 처리량
처리량 : 단위 시간당 시스템이 처리하는 작업량
- TPS : Transaction Per Second, 초당 트랜잭션 수
- RPS : Request Per Second, 초당 요청 수

![](/assets/images/jaehoo1/etc/tps.png)

요청이 최대 TPS를 초과하면 응답 시간이 지연된다. 응답 시간의 증가는 사용자 이탈로 이어질 수 있다. 이를 방지하려면 다음 2가지 (TPS를 높이는) 방법을 고려해야 한다.
- 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기 → Scale Up / Scale Out
- 처리 시간 자체를 줄여 대기 시간 줄이기 → 성능 튜닝 / 비동기 처리 등

## DB 커넥션 풀
DB를 사용하려면 다음과 같이 3단계를 거친다.
1. DB에 연결한다.
2. 쿼리를 실행한다.
3. 사용이 끝나면 연결을 종료한다.

네트워크에서 DB를 연결하고 종료하는 시간은 전체 응답 시간에 영향을 준다. 이런 문제를 피하기 위해 DB 커넥션 풀을 사용한다. **DB 커넥션 풀은 DB에 연결된 커넥션을 미리 생성해서 보관한다.** 애플리케이션은 DB 작업이 필요할 때 풀에서 커넥션을 가져와 사용하고, 작업이 끝나면 다시 풀에 반환한다. **커넥션 풀을 사용하면 이미 연결된 커넥션을 재사용하기 때문에 응답 시간이 줄어드는 장점이 있다.**

많이 사용하는 프레임워크나 언어도 DB 커넥션 풀을 지원한다. 서버 개발에서 DB 커넥션 풀을 사용하는 것은 필수라는 얘기다. **스프링 부트는 HikariCP를 커넥션 풀로 사용**하며 Go 언어는 자체적으로 DB 커넥션 풀을 지원할 정도다.

커넥션 풀은 다양한 설정을 제공한다. 그중 중요한 설정은 다음과 같다.
- 커넥션 풀 크기(또는 최소 크기, 최대 크기)
- 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기할 시간
- 커넥션 유지 시간(최대 유휴 시간, 최대 유지 시간)

## 메모리 사용
메모리 사용을 줄이면 GC 시간도 줄어들 가능성이 높아진다. 예를 들어 JVM에 할당된 최대 힙 크기를 4GB에서 2GB로 줄이면 GC가 탐지하고 제거해야 할 미사용 객체의 개수와 크기도 줄어든다. 검사해야 할 객체 수가 줄어드는 만큼 GC 수행 시간도 짧아진다. 물론 실제 애플리케이션이 4GB에 가까운 메모리가 있어야 하는 데도 2GB로 줄이면 메모리 부족으로 에러가 발생할 수 있으므로 실제 메모리 사용 패턴에 맞게 최대 힙 크기를 조정해야 한다.

한 번에 대량으로 객체를 생성하는 것도 주의해야 한다. 대량으로 객체가 생성되는 것을 방지하려면 조회 범위를 제한해야 한다.

파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용한다. 다음 자바 코드처럼 파일 데이터를 한꺼번에 메모리에 로딩한 후에 응답하는 방식은 피해야 한다. 파일 크기와 동시 사용자 수에 따라 메모리 사용량이 급증할 수 있기 때문이다. 이 코드는 30MB 크기의 파일을 100명이 동시에 다운로드하면 약 3GB의 메모리가 필요하게 된다.
```java
byte[] bytes = Files.readAllBytes(Path.of("path")); // 파일을 한 번에 메모리에 로딩
out.write(bytes);
```

스트림을 활용하면 파일 처리 과정에서 필요한 메모리 크기를 줄일 수 있다. 다음은 스트림을 이용하도록 변환한 코드이다.
```java
InputStream is = Files.newInputStream(Path.of("path"));
byte[] buffer = new byte[8192]; // 8KB 메모리
int read;
while ((read = is.read(buffer, 0, 8192)) >= 0) {
    out.write(buffer, 0, read);
}
// is.transferTo(out)와 동일 코드
```

이 코드는 파일을 한 번에 읽지 않고 8KB씩 끊어서 읽는다. 동시에 100명이 다운로드를 요청하더라도 필요한 메모리는 800KB에 불과하다. 파일 전체를 한 번에 메모리에 로딩하는 방식은 총 3GB에 가까운 메모리가 필요했는데, 이와 비교하면 스트림 방식은 0.001%도 안 되는 적은 메모리만을 사용하는 셈이다.

## 응답 데이터 압축
서버는 사용자의 네트워크 속도를 제어할 수 없지만 전송하는 데이터의 크기는 제어할 수 있다. 이때 사용할 수 있는 방법이 응답 데이터를 압축해서 전송하는 것이다. 웹 서버가 전송하는 응답 데이터 중에서 HTML, CSS, JS, JSON과 같이 텍스트로 구성된 응답은 압축하면 데이터 전송량을 크게 줄일 수 있다. 실제로 텍스트 데이터를 gzip으로 압축하면 70% 이상 크기를 줄일 수 있으며 데이터 전송 크기가 줄어든 만큼 전송 시간도 빨라진다. 즉, 응답 시간이 짧아진다.

아파치나 Nginx와 같은 웹 서버는 압축 기능을 제공하고 있으므로 약간의 설정만 추가하면 즉시 효과를 볼 수 있다.
> **Accept-Encoding 요청 헤더와 Content-Encoding 응답 헤더**
> 
> 웹 브라우저나 HTTP 클라이언트는 Accept-Encoding 헤더를 통해 서버에 처리할 수 있는 압축 알고리즘을 알린다. 예를 들어 gzip, deflate 알고리즘을 사용해서 압축을 풀 수 있다면 다음과 같이 Accept-Encoding 헤더를 전송한다.
> ```text
> Accept-Encoding: gzip, deflate
> ```
>
> 웹 서버는 Accept-Encoding 헤더에 명시된 알고리즘 중에서 자신이 지원하는 방식이 있을 경우, 해당 압축 알고리즘으로 응답 데이터를 압축해서 전송한다. 이때 사용된 압축 알고리즘은 Content-Encoding 응답 헤더를 통해 클라이언트에 전달된다.

응답 데이터를 압축할 때에는 다음 사항을 고려하자.
- html, css, js, json과 같은 텍스트 형식의 응답은 압축률이 높아 효과적이다. 반면 jpeg 이미지나 zip 파일처럼 이미 압축한 데이터에는 다시 압축해도 효과가 없다. 따라서 모든 응답에 압축을 적용하지 말고 텍스트 형식의 데이터에 압축을 적용하자.
- 웹 서버에서 압축을 적용했더라도 방화벽이 이를 해제해 응답할 수 있다. 즉, 웹 서버에 압축 설정을 적용했음에도 실제 응답 데이터가 압축되지 않았다면 방화벽 설정도 확인해야 한다.