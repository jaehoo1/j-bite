# 느려진 서비스, 어디부터 봐야 할까? - 응답 시간
응답 시간은 사용자의 요청을 처리하는 데 걸리는 시간을 의미한다.

전형적인 API 서버의 응답 시간은 다음의 시간들을 포함한다.

![](/assets/images/jaehoo1/etc/server-response-time.png)

- 서버에 연결, 서버로 데이터 전송
- 서버 실행(서버 처리 시간)
  - 로직 수행(`if`, `for` 등)(백엔드 로직)
  - DB 연동(SQL 실행)
  - 외부 API 연동
  - 응답 데이터 생성(전송)
- 서버 응답

응답 시간은 다음의 두 가지로 나누어 측정하기도 하는데
- TTFB(Time to First Byte) : 응답 데이터 중 첫 번째 바이트가 도착할 때까지 걸린 시간
- TTLB(Time to Last Byte) : 응답 데이터의 마지막 바이트가 도착할 때까지 걸린 시간

응답 데이터의 크기가 작다면 TTFB와 TTLB의 차이가 크지 않을 것이고, 파일 다운로드처럼 전송할 데이터가 크거나 네트워크 속도가 느리면 TTFB와 TTLB의 차이가 클 것이다.

서버 개발자는 주로 서버의 처리 시간을 확인하는데, 이 중 DB 연동과 내/외부 API 연동이 큰 비중을 차지한다. (서버 처리 시간 대부분의 병목)  
이러한 이유로 응답 시간을 줄일 때 DB 연동(과 API 연동) 시간에 집중한다.

## 처리량
처리량 : 단위 시간당 시스템이 처리하는 작업량
- TPS : Transaction Per Second, 초당 트랜잭션 수
- RPS : Request Per Second, 초당 요청 수

![](/assets/images/jaehoo1/etc/tps.png)

요청이 최대 TPS를 초과하면 응답 시간이 지연된다. 응답 시간의 증가는 사용자 이탈로 이어질 수 있다. 이를 방지하려면 다음 2가지 (TPS를 높이는) 방법을 고려해야 한다.
- 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기 → Scale Up / Scale Out
- 처리 시간 자체를 줄여 대기 시간 줄이기 → 성능 튜닝 / 비동기 처리 등

## DB 커넥션 풀
DB를 사용하려면 다음과 같이 3단계를 거친다.
1. DB에 연결한다.
2. 쿼리를 실행한다.
3. 사용이 끝나면 연결을 종료한다.

DB 커넥션의 생애주기:
- 데이터베이스 드라이버를 사용하여 데이터베이스에 연결
- 데이터 읽기/쓰기를 위한 TCP 소켓 열기
- 소켓을 통한 데이터 읽기/쓰기
- 연결 종료
- 소켓 닫기

네트워크에서 DB를 연결하고 종료하는 시간은 전체 응답 시간에 영향을 준다. 커넥션 풀이 없다면 애플리케이션에서 DB에 접근해야하는 요청을 처리할 때마다 커넥션을 새로 생성하여 연결하고 해제하는 과정을 반복해야 한다. 이 과정은 비용이 상당히 많이 들기 때문에 요청의 응답시간이 길어진다. 이런 문제를 피하기 위해 DB 커넥션 풀을 사용한다. **DB 커넥션 풀은 DB에 연결된 커넥션을 미리 생성해서 보관한다.** 애플리케이션은 DB 작업이 필요할 때 풀에서 커넥션을 가져와 사용하고, 작업이 끝나면 다시 풀에 반환한다. **커넥션 풀을 사용하면 이미 연결된 커넥션을 재사용하기 때문에 응답 시간이 줄어드는 장점이 있다.**

많이 사용하는 프레임워크나 언어도 DB 커넥션 풀을 지원한다. 서버 개발에서 DB 커넥션 풀을 사용하는 것은 필수라는 얘기다. **스프링 부트는 HikariCP를 커넥션 풀로 사용**하며 Go 언어는 자체적으로 DB 커넥션 풀을 지원할 정도다.

커넥션 풀은 다양한 설정을 제공한다. 그중 중요한 설정은 다음과 같다.
- 커넥션 풀 크기(또는 최소 크기, 최대 크기)
- 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기할 시간
- 커넥션 유지 시간(최대 유휴 시간, 최대 유지 시간)

**그럼 커넥션 풀 사이즈는 클 수록 좋은가?**  
커넥션을 사용하는 주체는 스레드(Thread)이기 때문에, 커넥션과 스레드를 연결지어 생각해야 한다. 만약 커넥션 풀 사이즈가 스레드 풀 사이즈보다 크면, 스레드가 모두 사용하지 못해서 리소스가 낭비된다. 반대로 커넥션 풀 사이즈가 스레드 풀 사이즈보다 작으면, 스레드가 커넥션이 반환되기를 기다려야 하기 때문에 작업이 지연된다.

커넥션 풀 사이즈와 스레드 풀 사이즈의 균형이 맞더라도, 너무 큰 사이즈로 설정하면 데이터베이스 서버, 애플리케이션 서버의 메모리와 CPU를 과도하게 사용하게 되므로 성능이 저하된다.

## 메모리 사용
메모리 사용을 줄이면 GC 시간도 줄어들 가능성이 높아진다. 예를 들어 JVM에 할당된 최대 힙 크기를 4GB에서 2GB로 줄이면 GC가 탐지하고 제거해야 할 미사용 객체의 개수와 크기도 줄어든다. 검사해야 할 객체 수가 줄어드는 만큼 GC 수행 시간도 짧아진다. 물론 실제 애플리케이션이 4GB에 가까운 메모리가 있어야 하는 데도 2GB로 줄이면 메모리 부족으로 에러가 발생할 수 있으므로 실제 메모리 사용 패턴에 맞게 최대 힙 크기를 조정해야 한다.

한 번에 대량으로 객체를 생성하는 것도 주의해야 한다. 대량으로 객체가 생성되는 것을 방지하려면 조회 범위를 제한해야 한다.

파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용한다. 다음 자바 코드처럼 파일 데이터를 한꺼번에 메모리에 로딩한 후에 응답하는 방식은 피해야 한다. 파일 크기와 동시 사용자 수에 따라 메모리 사용량이 급증할 수 있기 때문이다. 이 코드는 30MB 크기의 파일을 100명이 동시에 다운로드하면 약 3GB의 메모리가 필요하게 된다.
```java
byte[] bytes = Files.readAllBytes(Path.of("path")); // 파일을 한 번에 메모리에 로딩
out.write(bytes);
```

스트림을 활용하면 파일 처리 과정에서 필요한 메모리 크기를 줄일 수 있다. 다음은 스트림을 이용하도록 변환한 코드이다.
```java
InputStream is = Files.newInputStream(Path.of("path"));
byte[] buffer = new byte[8192]; // 8KB 메모리
int read;
while ((read = is.read(buffer, 0, 8192)) >= 0) {
    out.write(buffer, 0, read);
}
// is.transferTo(out)와 동일 코드
```

이 코드는 파일을 한 번에 읽지 않고 8KB씩 끊어서 읽는다. 동시에 100명이 다운로드를 요청하더라도 필요한 메모리는 800KB에 불과하다. 파일 전체를 한 번에 메모리에 로딩하는 방식은 총 3GB에 가까운 메모리가 필요했는데, 이와 비교하면 스트림 방식은 0.001%도 안 되는 적은 메모리만을 사용하는 셈이다.

## 응답 데이터 압축
서버는 사용자의 네트워크 속도를 제어할 수 없지만 전송하는 데이터의 크기는 제어할 수 있다. 이때 사용할 수 있는 방법이 응답 데이터를 압축해서 전송하는 것이다. 웹 서버가 전송하는 응답 데이터 중에서 HTML, CSS, JS, JSON과 같이 텍스트로 구성된 응답은 압축하면 데이터 전송량을 크게 줄일 수 있다. 실제로 텍스트 데이터를 gzip으로 압축하면 70% 이상 크기를 줄일 수 있으며 데이터 전송 크기가 줄어든 만큼 전송 시간도 빨라진다. 즉, 응답 시간이 짧아진다.

아파치나 Nginx와 같은 웹 서버는 압축 기능을 제공하고 있으므로 약간의 설정만 추가하면 즉시 효과를 볼 수 있다.
> **Accept-Encoding 요청 헤더와 Content-Encoding 응답 헤더**
> 
> 웹 브라우저나 HTTP 클라이언트는 Accept-Encoding 헤더를 통해 서버에 처리할 수 있는 압축 알고리즘을 알린다. 예를 들어 gzip, deflate 알고리즘을 사용해서 압축을 풀 수 있다면 다음과 같이 Accept-Encoding 헤더를 전송한다.
> ```text
> Accept-Encoding: gzip, deflate
> ```
>
> 웹 서버는 Accept-Encoding 헤더에 명시된 알고리즘 중에서 자신이 지원하는 방식이 있을 경우, 해당 압축 알고리즘으로 응답 데이터를 압축해서 전송한다. 이때 사용된 압축 알고리즘은 Content-Encoding 응답 헤더를 통해 클라이언트에 전달된다.

응답 데이터를 압축할 때에는 다음 사항을 고려하자.
- html, css, js, json과 같은 텍스트 형식의 응답은 압축률이 높아 효과적이다. 반면 jpeg 이미지나 zip 파일처럼 이미 압축한 데이터에는 다시 압축해도 효과가 없다. 따라서 모든 응답에 압축을 적용하지 말고 텍스트 형식의 데이터에 압축을 적용하자.
- 웹 서버에서 압축을 적용했더라도 방화벽이 이를 해제해 응답할 수 있다. 즉, 웹 서버에 압축 설정을 적용했음에도 실제 응답 데이터가 압축되지 않았다면 방화벽 설정도 확인해야 한다.

## Reference
- DB 커넥션 풀 - https://www.maeil-mail.kr/question/88


# 외부 연동이 문제일 때 살펴봐야 할 것들
연동하는 서비스에 장애가 발생하면 우리 서비스도 영향을 받는다. 서비스 간 연동이 많아질수록 연동 시스템의 품질도 함께 신경써야 한다. 이를 소홀히 하면 연동 서비스의 장애가 전체 서비스가 멈추는 장애로 이어질 수 있다.

연동 서비스의 문제를 완전히 차단하기는 어렵다. 연동 서비스가 필수인 경우도 있기 때문이다. 하지만 그 영향은 줄일 수 있다.

## 타임아웃
외부 연동에서 가장 중요한 설정 중 하나는 타임아웃이다. 위에서 처리량에 영향을 주는 요소 중 하나로 [응답 시간](#느려진-서비스-어디부터-봐야-할까---응답-시간)을 언급했는데, 타임아웃은 바로 이 응답 시간과 깊이 관련되어 있다. 연동 서비스를 호출할 때 타임아웃을 적절히 설정하지 않으면, 연동 서비스에 장애가 발생했을 때 전체 서비스의 품질이 급격히 나빠질 수 있다.

### 연결 타임아웃, 읽기 타임아웃
API 연동에서 통신 과정을 단순화해 표현하면 아래 그림처럼 연결, 요청, 응답, 종료의 4단계를 거친다.

![](/assets/images/jaehoo1/etc/connection-read-timeout.png)

첫 번째 단계는 네트워크 연결 시도 단계다. 연결에는 시간이 걸린다. 네트워크 상황이나 연결할 서버의 상태에 따라 연결에 오랜 시간이 걸릴 수 있다. 연결에 시간이 오래 걸리면 대기 시간도 함께 증가한다. 대기 시간이 무한정 길어지면 성능 문제가 발생하므로, 연결 타임아웃(connection timeout)을 설정해 연결 대기 시간을 제한해야 한다.

일단 연결이 되면 요청을 전송하고 응답을 기다리게 된다. 이때 응답을 받기까지 시간이 오래 걸리면 앞서 말한 대기 시간 문제가 다시 발생한다. 따라서 읽기 타임아웃(read timeout)을 설정해서 응답 대기 시간을 제한해야 한다.

타임아웃 시간이 너무 짧으면 연동 서비스가 정상 처리했음에도 불구하고 타임아웃 에러가 발생할 수 있다. 아래 그림은 이러한 상황을 나타낸다.

![](/assets/images/jaehoo1/etc/timeout-example.png)

1. 고객은 상품 결제를 커머스 서버에 요청한다.
2. 커머스 서버는 승인 처리를 위해 PG 서버 API를 호출한다. 이때 읽기 타임아웃을 5초로 지정한다.
3. PG 서버는 카드 결제를 위해 카드사 시스템과 통신을 시작한다. 카드사가 승인 처리하는 데 5초 이상 걸린다.
4. 커머스 서버는 PG 서버로부터 5초 동안 응답을 받지 못해 타임아웃 에러가 발생하며 상품 결제에 실패한다.
5. 커머스 서버는 고객에게 실패 응답을 전송한다.
6. 카드사 서버는 10초 만에 결제 승인에 성공하고 그 결과를 PG 서버에 응답한다.

이 과정이 끝나면 고객은 카드로는 결제했지만 상품은 구매하지 못하는 불쾌한 상황에 빠진다. 커머스 서버가 PG 서버와의 통신에서 타임아웃을 15초로 설정했다면 발생하지 않았을 문제다. 결제처럼 민감한 기능은 읽기 타임아웃 시간을 약간 길게 설정해서 간헐적으로 연동 시간이 길어지더라도 정상적으로 처리할 수 있어야 한다.

> ### 소켓 타임아웃과 읽기 타임아웃
>
> 읽기 타임아웃을 지정할 때는 실제로 설정하는 값이 무엇인지 확인해야 한다. 예를 들어 Apache HttpClient는 소켓 타임아웃을 설정한다. 소켓 타임아웃은 네트워크 패킷 단위를 기준으로 하므로, 전체 응답 시간에 대한 타임아웃을 의미하지는 않는다. 따라서 소켓 타임아웃을 5초로 지정해도 전체 응답 시간은 5초 이상 걸릴 수 있다.
>
> OkHttp는 읽기 타임아웃과는 별개로 호출 타임아웃(call timeout)을 설정할 수 있다. 호출 타임아웃은 요청 시작부터 응답까지의 전체 시간 기준으로 설정된다. 소켓 타임아웃을 5초로, 호출 타임아웃을 10초로 설정하면 패킷은 계속 수신되지만 전체 처리 시간이 오래 걸리는 경우에 타임아웃을 발생시킬 수 있다.

## 재시도
외부 연동에 실패했을 때 처리 방법 중 하나는 재시도를 하는 것이다. 네트워크 통신 과정에서 간헐적으로 연결에 실패하거나 일시적으로 응답이 느려지는 경우가 있다. 이럴 때는 재시도를 통해 연동 실패를 성공으로 바꿀 수 있다.

### 재시도 가능 조건
재시도를 통해 연동 실패를 줄일 수 있지만, 항상 재시도를 할 수 있는 것은 아니다. 연동 API를 다시 호출해도 되는 조건인지 확인해야 한다.

예를 들어 포인트 서비스가 제공하는 API를 호출해 포인트를 차감하는 상황을 생각해보자. 포인트 서비스를 호출하는 과정에서 읽기 타임아웃이 발생했을 때 재시도를 하게 되면 포인트 차감이 두 번 발생할 수 있다.

재시도를 해도 되는 조건은 다음 3가지로 정리할 수 있다.
- 단순 조회 기능
- 연결 타임아웃
- 멱등성(idempotent)을 가진 변경 기능

단순 조회 기능은 재시도를 통해 성공 확률을 높일 수 있다. 포인트 내역 조회 같은 기능은 다시 호출해도 포인트 중복 차감 같은 데이터 문제가 생기지 않는다. 일시적인 문제였다면 다시 조회할 경우 정상적으로 처리될 가능성이 높다.

연결 타임아웃도 마찬가지다. 연결 타임아웃이 발생했다는 것은 연동 서비스에 아직 연결되지 않은 상태라는 뜻이다. 연동 서비스가 요청을 처리하고 있지 않은 상태이므로, 순간적인 네트워크 문제였다면 재시도를 통해 연결에 성공할 가능성이 있다.

읽기 타임아웃은 재시도할 때 주의해야 한다. 이 경우는 이미 연동 서비스가 요청을 처리하고 있는 중이기 때문이다. 읽기 타임아웃이 발생한 상황에서 재시도를 하면 로직이 중복 수행되는 데이터 문제가 생길 수 있다.

상태를 변경하는 연동 API를 재시도할 때는 멱등성을 고려해야 한다. **멱등성**이란 **연산을 여러 번 적용해도 결과가 달라지지 않는 성질**을 말한다. 한 사용자가 여러 번 API를 실행해도 한 번만 반영된다. API를  실행하는 동안 읽기 타임아웃이 발생해서 재시도해도 데이터는 이상 상태를 갖지 않는다.

같은 API라도 실패 원인에 따라 재시도 여부를 결정해야 한다. 검증 오류가 발생했다면 재시도를 해도 동일하게 실패할 가능성이 높다. API를 호출할 때 잘못된 파라미터를 전달했다면 입력이 잘못 들어왔기 때문에 400 상태 코드를 응답할 것이다. 이때 잘못된 파라미터 요청을 다시 보내도 같은 이유로 실패하게 된다.

### 재시도 횟수와 간격
재시도할 때는 다음 2가지를 결정해야 한다.
- 재시도 횟수
- 재시도 간격

먼저 재시도 횟수를 결정한다. 재시도를 무한정 할 수는 없다. 재시도 횟수만큼 응답 시간도 함께 증가하기 때문이다. 대부분의 경우 1~2번 정도의 재시도가 적당하다. 2번 재시도를 하면 총 3번 시도한 것이 되는데, 이 모두 실패했다면 간헐적인 오류보다는 다른 근본적인 문제일 가능성이 높다. 이 경우에는 재시도해도 실패할 확률이 높다.

재시도 간격도 중요하다. 여러 차례 재시도할 때는 재시도 간격을 점진적으로 늘리기도 한다. 예를 들어 첫 번째 재시도는 1초 뒤에, 두 번째 재시도는 2초 뒤에 하는 식이다. 이를 통해 연동 서버에 가해지는 부하를 일부 완화할 수 있다.

### 재시도 폭풍(retry storm) 안티 패턴
재시도를 통해 성공 가능성을 높일 수 있지만, 반대로 연동 서비스에는 더 큰 부하를 줄 수 있다. 예를 들어 연동 서비스의 성능이 느려저서 읽기 타임아웃이 발생한 상황을 생각해보자. 이때 재시도를 하면, 연동 서비스는 같은 요청을 두 배로 받게 된다. 이전 요청을 아직 처리 중인데, 같은 클라이언트가 재시도로 또다시 요청을 보내는 것이다.

엎친 데 덮친 격으로, 성능이 느려진 상태에서 새로운 요청까지 더해지면 연동 서비스의 성능은 더 나빠진다. 따라서 재시도를 검토할 때는 연동 서비스의 성능 상황도 함께 고려해야 한다.

## 동시 요청 제한
연동 서비스가 한 번에 처리할 수 있는 동시 요청 수가 100개라고 하자. 이때 연동 서비스로 동시에 300개의 요청이 들어오면 어떻게 될까? 연동 서비스의 최대 처리량을 초과했기 때문에 응답 시간이 느려지기 시작할 것이다. 연동 서비스가 느려지면 우리 서비스도 함께 느려진다.

이런 문제는 순간적으로 트래픽이 몰릴 때 발생할 수 있다. 예를 들어 선착순 이벤트를 시작하면 사용자 트래픽이 급격히 증가한다. 이 트래픽이 연동 서비스로 그대로 전달되면, 연쇄적으로 응답 시간이 느려지는 상황이 발생할 수 있다.

연동 서비스에 임계치 이상의 요청을 보내면서 발생하는 성능 저하 문제를 완화하는 방법은 연동 서비스에 요청을 일정 수준 이상으로 보내지 않는 것이다. 연동 서비스가 동시에 처리할 수 있는 요청 개수가 100개라고 할 때, 우리 서비스가 연동 서비스로 보내는 동시 요청을 100개까지만 제한하면 연동 서비스는 성능 저하 문제 없이 안정적으로 처리할 수 있다. 연동 서비스로 보내지 않은 요청은 바로 에러를 응답한다. 503(Service Unavailable) HTTP 상태 코드를 사용하면 과부화 상황임을 클라이언트에 알려 알맞은 오류 메시지를 출력할 수 있다.

> ### 벌크헤드(Bulkhead)
> 동시 요청 수를 제한하지 않을 때 동시 요청 300개를 연동 서비스로 전달하는데, 연동 서비스의 응답이 느려지면서 우리 서비스의 응답도 함께 느려지고 우리 서비스의 나머지 기능에도 영향을 주게 된다.
>
> 동시 요청 수를 제한했다면 연동 서비스와 연동하는 요청이 동시에 300개 들어올 때, 100개는 처리되고 나머지 200개는 바로 에러 응답을 받는다. 연동 서비스와 연동하는 기능은 오류가 발생하지만, 연동 서비스를 연동하지 않는 나머지 기능은 정상 동작할 수 있다.
>
> 이렇게 동시 요청을 제한하는 방식은 벌크헤드 패턴을 활용한 것이다. 벌크헤드 패턴은 **각 구성 요소를 격리함으로써 한 구성 요소의 장애가 다른 구성 요소에 영향을 주지 않도록 하는 설계 패턴**이다.

## 서킷 브레이커
연동 서비스에 과부하가 발생해 응답을 제대로 주지 못하고 있는 상황이라고 하자. 연동 서비스가 정상화되기 전까지는 요청을 보내도 계속 에러만 발생한다. 또한, 읽기 타임아웃이 발생할 때까지 대기하느라 응답 시간도 길어질 것이다.

![](/assets/images/jaehoo1/etc/integration-service-outage.png)

B 서비스가 정상 상태가 아닐 때, A 서비스는 B 서비스에 요청을 보내지 않고 바로 에러를 응답하는 것이 낫다. 이렇게 하면 B 서비스의 문제가 A 서비스에 주는 영향(응답 시간 증가, 처리량 감소 등)을 줄일 수 있다.

또한 사용자 입장에서도 수 초를 대기하다가 에러 화면을 보는 것보다는, 빠르게 에러 화면을 보는 편이 낫다.

연동 서비스가 장애 상황일 때는 연동 대신 바로 에러를 응답하고, 정상화되었을 때 연동을 재개하면 연동 서비스의 장애가 주는 영향을 줄일 수 있다.

서킷 브레이커(circuit breaker)가 동작하는 방식이 바로 이와 같다.

서킷 브레이커는 누전 차단기와 비슷하게 동작한다. 과전류가 흐르면 차단기가 내려가 전기를 끊는 것처럼, 서킷 브레이커도 과도한 오류가 발생하면 연동을 중지시키고 바로 에러를 응답한다. 이렇게 하면 연동 서비스로의 요청 전달을 차단할 수 있다.

서킷 브레이커는 닫힘(closed), 열림(open), 반 열림(half-open)의 3가지 상태를 갖는다.

![](/assets/images/jaehoo1/etc/curcuit-breaker.png)

서킷 브레이커는 닫힘 상태(정상)로 시작한다. 닫힘 상태일 때는 모든 요청을 연동 서비스에 전달한다. 외부 연동 과정에서 오류가 발생하기 시작하면, 지정한 임계치를 초과했는지 확인한다. 실패 건수가 임계치를 초과하면 서킷 브레이커는 열림 상태가 된다. 보통 임계치는 다음 조건 중 하나를 사용한다.
- 시간 기준 오류 발생 비율: 예) 10초 동안 오류 비율이 50% 초과
- 개수 기준 오류 발생 비율: 예) 100개 요청 중 오류 비율이 50% 초과

열림 상태가 되면 연동 요청은 수행하지 않고, 바로 에러 응답을 리턴한다. 열림 상태는 지정된 시간 동안 유지된다. 이 시간이 지나면 반 열림 상태로 전환된다. 반 열림 상태가 되면 일부 요청에 한해 연동을 시도한다. 일정 개수 또는 일정 시간 동안 반 열림 상태를 유지하며, 이 기간 동안 연동에 성공하면 닫힘 상태로 복귀한다. 반대로 연동에 실패하면 다시 열림 상태로 전환되어 연동을 차단한다.

서킷 브레이커가 열려 있는 동안은 연동 서비스에 요청이 전달되지 않기 때문에 연동 서비스가 과부하 상황에서 벗어날 수 있는 기회도 생긴다.

> ### 빠른 실패
> 서킷 브레이커는 문제 상황이 감지되면 해당 기능을 더 이상 실행하지 않고 바로 실패로 처리한다. 이처럼 **실패를 빠르게 감지하고, 문제가 있는 기능을 실행하지 않고 중단시키는 방식**을 빠른 실패(fail fast)라고 한다.
>
> 빠른 실패는 장애가 발생한 기능에 부하가 더해지는 것을 방지할 뿐 아니라, 불필요한 자원 낭비를 줄여 전체 서비스의 안정성을 유지하는 데도 도움이 된다.

## 외부 연동과 DB 연동
회원 가입 요청을 처리할 때, 외부 서비스를 호출해 회원 정보를 전달하는 상황을 생각해보자. 모든 것이 정상이라면 DB에 회원 데이터가 저장되고, 외부 서비스의 저장소에도 정보가 잘 저장될 것이다. 하지만 모든 것이 항상 성공하는 것은 아니다. DB에 데이터를 저장하는 과정에서 실패할 수도 있고, 외부 서비스를 연동하는 도중에 에러가 발생할 수도 있다.

### 외부 연동과 트랜잭션 처리
DB 연동과 외부 연동을 함께 실행할 때는, 오류 발생 시 DB 트랜잭션을 어떻게 처리할지 알맞게 판단해야 한다. 다음은 흔히 발생할 수 있는 2가지 상황이다.
- [외부 연동에 실패했을 때 트랜잭션을 롤백](#외부-연동에-실패했을-때-트랜잭션을-롤백)
- [외부 연동은 성공했지만 DB 연동에 실패해 트랜잭션을 롤백](#외부-연동은-성공했는데-db-연동에-실패해서-트랜잭션을-롤백)

#### 외부 연동에 실패했을 때 트랜잭션을 롤백
먼저, 트랜잭션 범위 안에서 외부 연동에 실패한 경우, 트랜잭션을 롤백할 수 있다.

![](/assets/images/jaehoo1/etc/transaction-api-db-failure1.png)

외부 연동에 실패했을 때 트랜잭션을 롤백하면, 변경한 데이터가 DB에 반영되지 않는다. 단순한 방식이지만, 롤백을 통해 DB 데이터에 이상이 생기는 것을 방지할 수 있다.

하지만 읽기 타임아웃이 발생해 트랜잭션을 롤백할 때는, 외부 서비스가 실제로는 성공적으로 처리했을 가능성을 염두에 두어야 한다. 아래 그림은 이러한 상황을 보여준다.

![](/assets/images/jaehoo1/etc/transaction-api-db-failure2.png)

트랜잭션을 롤백했는데 외부 서비스가 실제로는 성공했을 경우, 2가지 방법 중 하나를 검토해야 한다. 첫 번째는 일정 주기로 두 시스템의 데이터가 일치하는지 확인하고 보정하는 방법이다. 예를 들어, 주문 서비스와 포인트 서비스가 하루에 한 번씩 전날 포인트 사용 내역을 비교해 불일치 건이 있는지 확인하는 식이다. 불일치 건이 발견되면 수동으로 또는 자동으로 보정한다.

두 번째는 성공 확인 API를 호출하는 방식이다. 읽기 타임아웃이 발생한 경우, 일정 시간 후에 이전 호출이 실제로 성공했는지 확인하는 API를 호출한다. 이때 성공 응답이 오면 트랜잭션을 지속하고, 실패 응답이 오면 트랜잭션을 롤백한다. 이 방식은 연동 서비스가 성공 여부를 알려주는 API를 제공할 때만 사용할 수 있다.

이 방식의 변형으로 취소 API를 호출하는 방법도 있다. 읽기 타임아웃이 발생한 뒤 일정 시간 후에 취소 API를 호출하는 것이다. 연동 서비스는 취소할 대상이 있으면 취소 처리를 수행한 뒤 성공 응답을 주고, 취소할 게 없다면 아무 동작 없이 성공 응답만 반환한다. 이 경우에는 연동 처리를 취소했으므로 트랜잭션을 롤백하면 된다.

단, 성공 확인 API나 취소 API를 호출하는 방식은 연동 서비스가 지원할 때만 사용할 수 있다. 또한, 이 API들을 호출하는 과정에서도 읽기 타임아웃이 발생할 수 있다.

따라서 두 시스템 간 데이터 일관성이 중요한 기능이라면 정기적으로 데이터 일치를 확인하는 프로세스를 갖추는 것이 바람직하다.

#### 외부 연동은 성공했는데 DB 연동에 실패해서 트랜잭션을 롤백
외부 연동은 성공했지만, DB 연동에 실패해 트랜잭션을 롤백한 경우에는 취소 API를 호출해 외부 연동을 이전 상태로 되돌리는 것이 필요하다. DB 연동에 실패했기 때문에 이 경우에는 성공 확인 API를 호출해도 의미가 없다.

![](/assets/images/jaehoo1/etc/transaction-api-db-failure3.png)

취소 API가 없거나 취소에 실패할 수도 있기 때문에 데이터 일관성이 중요한 서비스라면 일정 주기로 데이터가 맞는지 비교하는 프로세스를 갖추는 것이 좋다.

## HTTP 커넥션 풀
웹 브라우저의 개발자 도구를 활용해 인터넷 URL의 처리 시간을 분석한 결과 콘텐츠 다운로드에 걸린 전체 시간은 약 0.1초인데, 이 중 서버에 연결하는 데 걸린 시간은 0.047초로 약 47%를 차지하고 있다.

DB 커넥션 풀이 DB 연결에 걸리는 시간을 줄여 성능을 높이는 것처럼 HTTP 연결도 커넥션 풀을 사용하면 연결 시간을 줄일 수 있어 응답 속도 향상에 도움이 된다.

HTTP 커넥션 풀을 사용할 때는 다음 3가지를 고려해야 한다.
- HTTP 커넥션 풀의 크기
- 풀에서 HTTP 커넥션을 가져올 때까지 대기하는 시간
- HTTP 커넥션을 유지할 시간(keep alive)

HTTP 커넥션 풀을 사용할 때 가장 먼저 고려해야 할 값은 풀의 크기다. 풀의 크기는 연동할 서비스의 성능에 따라 결정해야 한다. 연동 서비스의 성능을 고려하지 않고 무턱대고 커넥션 풀 크기를 늘리면 순간적으로 트래픽이 몰릴 때 연동 서비스의 응답 시간이 급격히 느려질 수 있다. 그 결과, 연동 서비스의 성능 저하가 우리 서비스 전체의 응답 시간까지 느리게 만들 수 있다. 따라서 커넥션 풀의 크기를 설정할 때는 반드시 연동 서비스의 처리 능력을 고려해야 한다.

두 번째 고려 사항은 대기 시간이다. 예를 들어, HTTP 커넥션 풀의 크기가 10이라면 동시에 11개의 외부 연동 요청이 들어올 경우 10개는 커넥션을 확보해 실행되고, 남은 1개는 커넥션이 반환될 때까지 대기하게 된다. 대기 시간이 길어지면 전체 응답 시간도 함께 늘어나므로 대기 시간은 수 초 이내의 짧은 시간으로 설정하는 것이 좋다.

너무 짧게(예: 0.1초) 설정하면 일시적인 트래픽 증가에도 커넥션을 구하지 못해 에러가 발생할 수 있다. 반대로 너무 길게(예: 10초) 설정하면 연동 서버가 느려졌을 때 전체 응답 시간이 늘어나는 문제가 발생할 수 있다.

세 번째 고려 사항은 커넥션 유지 시간이다. 커넥션은 무한정 유지되지 않는다. 연동 서비스가 일정 시간 동안만 커넥션을 유지한 뒤 연결을 끊는 경우도 있다. 끊어진 커넥션을 사용하면 에러가 발생하므로 연동 서비스에 맞춰 유지 시간을 적절히 설정해야 한다. 예를 들어, HTTP/1.1에서는 서버가 Keep-Alive 헤더로 연결 유지 시간을 지정한다. 이 시간이 지나면 서버는 연결을 끊기 때문에, 클라이언트의 커넥션 풀도 이 값보다 더 오래 커넥션을 유지하면 안 된다.

## 연동 서비스 이중화
서비스가 대량 트래픽을 처리할 만큼 성장했다면 연동 서비스의 이중화를 고려해야 한다.

예를 들어 결제 서비스를 생각해보자. 쇼핑 서비스에서 결제는 핵심 기능이다. 결제가 되지 않으면 상품을 구매할 수 없기 때문이다. 이때 연동된 외부 결제 서비스에 장애가 발생하면, 장애가 발생한 시간 동안 쇼핑 서비스의 매출은 0원이 된다.

하지만 결제 서비스를 이중화해두면 한 곳에 장애가 발생해도 다른 결제 서비스를 이용해 결제를 계속 진행할 수 있다.

여력이 된다면 핵심 연동 서비스를 이중화해서 장애애 대응한다. 물론 연동 기능을 이중화하면 연동할 서비스가 늘어나고 그만큼 개발과 유지에 드는 비용도 증가한다. 즉, 비용이 배로 들 수 있다는 의미다. 그래서 연동 서비스를 이중화할지 여부를 결정할 때는 다음 2가지를 반드시 따져봐야 한다.
- 해당 기능이 서비스의 핵심인지 여부
- 이중화 비용이 감당 가능한 수준인지

핵심이 아닌 기능에 예산을 쓰는 건 쉽지 않다. 예를 들어, 쇼핑 서비스에서 결제는 핵심 기능이므로 이중화의 필요성을 설득할 수 있다. 반면에 로그 유실 방지를 위해 로그 수집 연동을 이중화하자고 설득하는 건 어렵다. 또한 재정적으로 이중화를 감당할 수 있어야 한다. 연동 서비스 장애로 인한 손실보다 이중화에 드는 비용이 더 크다면 이중화를 결정하기는 쉽지 않을 것이다.